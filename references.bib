@article{akataResearchAgendaHybrid2020,
  title = {A {{Research Agenda}} for {{Hybrid Intelligence}}: {{Augmenting Human Intellect With Collaborative}}, {{Adaptive}}, {{Responsible}}, and {{Explainable Artificial Intelligence}}},
  shorttitle = {A {{Research Agenda}} for {{Hybrid Intelligence}}},
  author = {Akata, Zeynep and Balliet, Dan and {de Rijke}, Maarten and Dignum, Frank and Dignum, Virginia and Eiben, Guszti and Fokkens, Antske and Grossi, Davide and Hindriks, Koen and Hoos, Holger and Hung, Hayley and Jonker, Catholijn and Monz, Christof and Neerincx, Mark and Oliehoek, Frans and Prakken, Henry and Schlobach, Stefan and {van der Gaag}, Linda and {van Harmelen}, Frank and {van Hoof}, Herke and {van Riemsdijk}, Birna and {van Wynsberghe}, Aimee and Verbrugge, Rineke and Verheij, Bart and Vossen, Piek and Welling, Max},
  year = {2020},
  month = aug,
  journal = {Computer},
  volume = {53},
  number = {8},
  pages = {18--28},
  issn = {1558-0814},
  doi = {10.1109/MC.2020.2996587},
  abstract = {We define hybrid intelligence (HI) as the combination of human and machine intelligence, augmenting human intellect and capabilities instead of replacing them and achieving goals that were unreachable by either humans or machines. HI is an important new research focus for artificial intelligence, and we set a research agenda for HI by formulating four challenges.},
  keywords = {Adaptive systems,Artificial intelligence,Machine intelligence,Task analysis,Teamwork,Tools},
  file = {/Users/didi/Zotero/storage/I2XNGK33/Akata et al. - 2020 - A Research Agenda for Hybrid Intelligence Augment.pdf}
}

@article{amershiPowerPeopleRole2014,
  title = {Power to the {{People}}: {{The Role}} of {{Humans}} in {{Interactive Machine Learning}}},
  shorttitle = {Power to the {{People}}},
  author = {Amershi, Saleema and Cakmak, Maya and Knox, William Bradley and Kulesza, Todd},
  year = {2014},
  month = dec,
  journal = {AI Magazine},
  volume = {35},
  number = {4},
  pages = {105--120},
  issn = {2371-9621},
  doi = {10.1609/aimag.v35i4.2513},
  urldate = {2023-04-05},
  abstract = {Intelligent systems that learn interactively from their end-users are quickly becoming widespread. Until recently, this progress has been fueled mostly by advances in machine learning; however, more and more researchers are realizing the importance of studying users of these systems. In this article we promote this approach and demonstrate how it can result in better user experiences and more effective learning systems. We present a number of case studies that characterize the impact of interactivity, demonstrate ways in which some existing systems fail to account for the user, and explore new ways for learning systems to interact with their users. We argue that the design process for interactive machine learning systems should involve users at all stages: explorations that reveal human interaction patterns and inspire novel interaction methods, as well as refinement stages to tune details of the interface and choose among alternatives. After giving a glimpse of the progress that has been made so far, we discuss the challenges that we face in moving the field forward.},
  copyright = {Copyright (c)},
  langid = {english},
  keywords = {Interactive Machine Learning},
  file = {/Users/didi/Zotero/storage/CY2NRMDU/Amershi et al. - 2014 - Power to the People The Role of Humans in Interac.pdf}
}

@book{armerComputersThoughtCollection1963,
  title = {Computers and {{Thought}}: {{A Collection}} of {{Articles}}},
  shorttitle = {Computers and {{Thought}}},
  author = {Armer, Paul},
  year = {1963},
  publisher = {{McGraw-Hill}},
  googlebooks = {GVMLAQAAIAAJ},
  langid = {english}
}

@misc{bangMultitaskMultilingualMultimodal2023,
  title = {A {{Multitask}}, {{Multilingual}}, {{Multimodal Evaluation}} of {{ChatGPT}} on {{Reasoning}}, {{Hallucination}}, and {{Interactivity}}},
  author = {Bang, Yejin and Cahyawijaya, Samuel and Lee, Nayeon and Dai, Wenliang and Su, Dan and Wilie, Bryan and Lovenia, Holy and Ji, Ziwei and Yu, Tiezheng and Chung, Willy and Do, Quyet V. and Xu, Yan and Fung, Pascale},
  year = {2023},
  month = feb,
  number = {arXiv:2302.04023},
  eprint = {2302.04023},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2302.04023},
  urldate = {2023-04-05},
  abstract = {This paper proposes a framework for quantitatively evaluating interactive LLMs such as ChatGPT using publicly available data sets. We carry out an extensive technical evaluation of ChatGPT using 23 data sets covering 8 different common NLP application tasks. We evaluate the multitask, multilingual and multi-modal aspects of ChatGPT based on these data sets and a newly designed multimodal dataset. We find that ChatGPT outperforms LLMs with zero-shot learning on most tasks and even outperforms fine-tuned models on some tasks. We find that it is better at understanding non-Latin script languages than generating them. It is able to generate multimodal content from textual prompts, via an intermediate code generation step. Moreover, we find that ChatGPT is 63.41\% accurate on average in 10 different reasoning categories under logical reasoning, non-textual reasoning, and commonsense reasoning, hence making it an unreliable reasoner. It is, for example, better at deductive than inductive reasoning. ChatGPT suffers from hallucination problems like other LLMs and it generates more extrinsic hallucinations from its parametric memory as it does not have access to an external knowledge base. Finally, the interactive feature of ChatGPT enables human collaboration with the underlying LLM to improve its performance, i.e, 8\% ROUGE-1 on summarization and 2\% ChrF++ on machine translation, in a multi-turn "prompt engineering" fashion. We also release codebase for evaluation set extraction.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/didi/Zotero/storage/ATM65Q4Q/Bang et al. - 2023 - A Multitask, Multilingual, Multimodal Evaluation o.pdf;/Users/didi/Zotero/storage/K2A5Z6U2/2302.html}
}

@inproceedings{boffEthicsScholarsAcademic2012,
  title = {Ethics {{Among Scholars}} in {{Academic Publishing}}},
  author = {Boff, Gina M.},
  year = {2012},
  urldate = {2023-04-27},
  abstract = {This paper offers a survey of the contemporary and common-place ethical breaches concerning authorship, research, and publishing in today’s scholarly production, as juxtaposed with some of the predominant standards and guidelines that have been developed to direct academic publishing practices. While the paper may suggest the need for an updated and comprehensive set of guidelines for multiple discipline areas, the purpose here is to prepare the theoretical framework for a future computing discipline-specific study of ethical authorship and related concepts in academia.}
}

@misc{bommasaniOpportunitiesRisksFoundation2022,
  title = {On the {{Opportunities}} and {{Risks}} of {{Foundation Models}}},
  author = {Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and {von Arx}, Sydney and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and Brynjolfsson, Erik and Buch, Shyamal and Card, Dallas and Castellon, Rodrigo and Chatterji, Niladri and Chen, Annie and Creel, Kathleen and Davis, Jared Quincy and Demszky, Dora and Donahue, Chris and Doumbouya, Moussa and Durmus, Esin and Ermon, Stefano and Etchemendy, John and Ethayarajh, Kawin and {Fei-Fei}, Li and Finn, Chelsea and Gale, Trevor and Gillespie, Lauren and Goel, Karan and Goodman, Noah and Grossman, Shelby and Guha, Neel and Hashimoto, Tatsunori and Henderson, Peter and Hewitt, John and Ho, Daniel E. and Hong, Jenny and Hsu, Kyle and Huang, Jing and Icard, Thomas and Jain, Saahil and Jurafsky, Dan and Kalluri, Pratyusha and Karamcheti, Siddharth and Keeling, Geoff and Khani, Fereshte and Khattab, Omar and Koh, Pang Wei and Krass, Mark and Krishna, Ranjay and Kuditipudi, Rohith and Kumar, Ananya and Ladhak, Faisal and Lee, Mina and Lee, Tony and Leskovec, Jure and Levent, Isabelle and Li, Xiang Lisa and Li, Xuechen and Ma, Tengyu and Malik, Ali and Manning, Christopher D. and Mirchandani, Suvir and Mitchell, Eric and Munyikwa, Zanele and Nair, Suraj and Narayan, Avanika and Narayanan, Deepak and Newman, Ben and Nie, Allen and Niebles, Juan Carlos and Nilforoshan, Hamed and Nyarko, Julian and Ogut, Giray and Orr, Laurel and Papadimitriou, Isabel and Park, Joon Sung and Piech, Chris and Portelance, Eva and Potts, Christopher and Raghunathan, Aditi and Reich, Rob and Ren, Hongyu and Rong, Frieda and Roohani, Yusuf and Ruiz, Camilo and Ryan, Jack and Ré, Christopher and Sadigh, Dorsa and Sagawa, Shiori and Santhanam, Keshav and Shih, Andy and Srinivasan, Krishnan and Tamkin, Alex and Taori, Rohan and Thomas, Armin W. and Tramèr, Florian and Wang, Rose E. and Wang, William and Wu, Bohan and Wu, Jiajun and Wu, Yuhuai and Xie, Sang Michael and Yasunaga, Michihiro and You, Jiaxuan and Zaharia, Matei and Zhang, Michael and Zhang, Tianyi and Zhang, Xikun and Zhang, Yuhui and Zheng, Lucia and Zhou, Kaitlyn and Liang, Percy},
  year = {2022},
  month = jul,
  number = {arXiv:2108.07258},
  eprint = {2108.07258},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2108.07258},
  urldate = {2023-04-04},
  abstract = {AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Machine Learning},
  file = {/Users/didi/Zotero/storage/TYEANH4R/Bommasani et al. - 2022 - On the Opportunities and Risks of Foundation Model.pdf;/Users/didi/Zotero/storage/9644ND75/2108.html}
}

@misc{brownLanguageModelsAre2020,
  title = {Language {{Models}} Are {{Few-Shot Learners}}},
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and {Herbert-Voss}, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  year = {2020},
  month = jul,
  number = {arXiv:2005.14165},
  eprint = {2005.14165},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2005.14165},
  urldate = {2023-04-26},
  abstract = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/didi/Zotero/storage/QPG534ZA/Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf;/Users/didi/Zotero/storage/JE822HYY/2005.html}
}

@article{caneseMultiAgentReinforcementLearning2021,
  title = {Multi-{{Agent Reinforcement Learning}}: {{A Review}} of {{Challenges}} and {{Applications}}},
  shorttitle = {Multi-{{Agent Reinforcement Learning}}},
  author = {Canese, Lorenzo and Cardarilli, Gian Carlo and Di Nunzio, Luca and Fazzolari, Rocco and Giardino, Daniele and Re, Marco and Spanò, Sergio},
  year = {2021},
  month = jan,
  journal = {Applied Sciences},
  volume = {11},
  number = {11},
  pages = {4948},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2076-3417},
  doi = {10.3390/app11114948},
  urldate = {2023-04-15},
  abstract = {In this review, we present an analysis of the most used multi-agent reinforcement learning algorithms. Starting with the single-agent reinforcement learning algorithms, we focus on the most critical issues that must be taken into account in their extension to multi-agent scenarios. The analyzed algorithms were grouped according to their features. We present a detailed taxonomy of the main multi-agent approaches proposed in the literature, focusing on their related mathematical models. For each algorithm, we describe the possible application fields, while pointing out its pros and cons. The described multi-agent algorithms are compared in terms of the most important characteristics for multi-agent reinforcement learning applications—namely, nonstationarity, scalability, and observability. We also describe the most common benchmark environments used to evaluate the performances of the considered methods.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {machine learning,multi-agent,reinforcement learning,swarm},
  file = {/Users/didi/Zotero/storage/3MLEJ229/Canese et al. - 2021 - Multi-Agent Reinforcement Learning A Review of Ch.pdf}
}

@article{carrollUtilityLearningHumans2019,
  title = {On the {{Utility}} of {{Learning}} about {{Humans}} for {{Human-AI Coordination}}},
  author = {Carroll, Micah and Shah, Rohin and Ho, Mark K. and Griffiths, T. and Seshia, S. and Abbeel, P. and Dragan, A.},
  year = {2019},
  month = oct,
  journal = {ArXiv},
  urldate = {2023-04-17},
  abstract = {While we would like agents that can coordinate with humans, current algorithms such as self-play and population-based training create agents that can coordinate with themselves. Agents that assume their partner to be optimal or similar to them can converge to coordination protocols that fail to understand and be understood by humans. To demonstrate this, we introduce a simple environment that requires challenging coordination, based on the popular game Overcooked, and learn a simple model that mimics human play. We evaluate the performance of agents trained via self-play and population-based training. These agents perform very well when paired with themselves, but when paired with our human model, they are significantly worse than agents designed to play with the human model. An experiment with a planning algorithm yields the same conclusion, though only when the human-aware planner is given the exact human model that it is playing with. A user study with real humans shows this pattern as well, though less strongly. Qualitatively, we find that the gains come from having the agent adapt to the human's gameplay. Given this result, we suggest several approaches for designing agents that learn about humans in order to better coordinate with them. Code is available at https://github.com/HumanCompatibleAI/overcooked\_ai.},
  file = {/Users/didi/Zotero/storage/3JI9QJNB/Carroll et al. - 2019 - On the Utility of Learning about Humans for Human-.pdf}
}

@article{chipereCriticalEvaluationAI2020,
  title = {Critical {{Evaluation}} of {{AI System Implementation}} as a {{Source}} of {{Competitive Advantage}}},
  author = {Chipere, Tendai Patience and Chen, Sijing},
  year = {2020},
  journal = {Journal of Marketing and Consumer Research},
  volume = {74},
  number = {0},
  pages = {19},
  issn = {Pending},
  urldate = {2023-04-02},
  abstract = {Critical Evaluation of AI System Implementation as a Source of Competitive Advantage},
  langid = {english},
  file = {/Users/didi/Zotero/storage/KMHRA6D2/Chipere and Chen - 2020 - Critical Evaluation of AI System Implementation as.pdf}
}

@article{CollaborativeIntelligenceHumans2018,
  title = {Collaborative {{Intelligence}}: {{Humans}} and {{AI Are Joining Forces}}},
  shorttitle = {Collaborative {{Intelligence}}},
  year = {2018},
  month = jul,
  journal = {Harvard Business Review},
  issn = {0017-8012},
  urldate = {2023-04-03},
  abstract = {Examples of how they’re enhancing each other’s strengths.},
  chapter = {Developing employees},
  keywords = {AI and machine learning,Automation,Developing employees,Information technology and telecom sector,Operations strategy},
  file = {/Users/didi/Zotero/storage/SGCWE4XS/collaborative-intelligence-humans-and-ai-are-joining-forces.html}
}

@article{cremerAIShouldAugment2021,
  title = {{{AI Should Augment Human Intelligence}}, {{Not Replace It}}},
  author = {Cremer, David De and Kasparov, Garry},
  year = {2021},
  month = mar,
  journal = {Harvard Business Review},
  issn = {0017-8012},
  urldate = {2023-04-03},
  abstract = {Will smart machines really replace human workers? Probably not. People and AI both bring different abilities and strengths to the table. The real question is: how can human intelligence work with artificial intelligence to produce augmented intelligence. Chess Grandmaster Garry Kasparov offers some unique insight here. After losing to IBM’s Deep Blue, he began to experiment how a computer helper changed players’ competitive advantage in high-level chess games. What he discovered was that having the best players and the best program was less a predictor of success than having a really good process. Put simply, “Weak human + machine + better process was superior to a strong computer alone and, more remarkably, superior to a strong human + machine + inferior process.” As leaders look at how to incorporate AI into their organizations, they’ll have to manage expectations as AI is introduced, invest in bringing teams together and perfecting processes, and refine their own leadership abilities.},
  chapter = {Business and society},
  keywords = {AI and machine learning,Algorithms,Automation,Business and society,Leadership,Technology and analytics},
  file = {/Users/didi/Zotero/storage/CUZQR54Q/ai-should-augment-human-intelligence-not-replace-it.html}
}

@misc{daiWhyCanGPT2022,
  title = {Why {{Can GPT Learn In-Context}}? {{Language Models Secretly Perform Gradient Descent}} as {{Meta-Optimizers}}},
  shorttitle = {Why {{Can GPT Learn In-Context}}?},
  author = {Dai, Damai and Sun, Yutao and Dong, Li and Hao, Yaru and Sui, Zhifang and Wei, Furu},
  year = {2022},
  month = dec,
  number = {arXiv:2212.10559},
  eprint = {2212.10559},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2212.10559},
  urldate = {2023-04-04},
  abstract = {Large pretrained language models have shown surprising In-Context Learning (ICL) ability. With a few demonstration input-label pairs, they can predict the label for an unseen input without additional parameter updates. Despite the great success in performance, the working mechanism of ICL still remains an open problem. In order to better understand how ICL works, this paper explains language models as meta-optimizers and understands ICL as a kind of implicit finetuning. Theoretically, we figure out that the Transformer attention has a dual form of gradient descent based optimization. On top of it, we understand ICL as follows: GPT first produces meta-gradients according to the demonstration examples, and then these meta-gradients are applied to the original GPT to build an ICL model. Experimentally, we comprehensively compare the behavior of ICL and explicit finetuning based on real tasks to provide empirical evidence that supports our understanding. The results prove that ICL behaves similarly to explicit finetuning at the prediction level, the representation level, and the attention behavior level. Further, inspired by our understanding of meta-optimization, we design a momentum-based attention by analogy with the momentum-based gradient descent algorithm. Its consistently better performance over vanilla attention supports our understanding again from another aspect, and more importantly, it shows the potential to utilize our understanding for future model designing.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/didi/Zotero/storage/YYYGNX7M/Dai et al. - 2022 - Why Can GPT Learn In-Context Language Models Secr.pdf;/Users/didi/Zotero/storage/A54ZLX9H/2212.html}
}

@misc{dangHowPromptOpportunities2022,
  title = {How to {{Prompt}}? {{Opportunities}} and {{Challenges}} of {{Zero-}} and {{Few-Shot Learning}} for {{Human-AI Interaction}} in {{Creative Applications}} of {{Generative Models}}},
  shorttitle = {How to {{Prompt}}?},
  author = {Dang, Hai and Mecke, Lukas and Lehmann, Florian and Goller, Sven and Buschek, Daniel},
  year = {2022},
  month = sep,
  number = {arXiv:2209.01390},
  eprint = {2209.01390},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2209.01390},
  urldate = {2023-04-26},
  abstract = {Deep generative models have the potential to fundamentally change the way we create high-fidelity digital content but are often hard to control. Prompting a generative model is a promising recent development that in principle enables end-users to creatively leverage zero-shot and few-shot learning to assign new tasks to an AI ad-hoc, simply by writing them down. However, for the majority of end-users writing effective prompts is currently largely a trial and error process. To address this, we discuss the key opportunities and challenges for interactive creative applications that use prompting as a new paradigm for Human-AI interaction. Based on our analysis, we propose four design goals for user interfaces that support prompting. We illustrate these with concrete UI design sketches, focusing on the use case of creative writing. The research community in HCI and AI can take these as starting points to develop adequate user interfaces for models capable of zero- and few-shot learning.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Human-Computer Interaction,H.5.2,I.2.7},
  file = {/Users/didi/Zotero/storage/D68QH2BA/Dang et al. - 2022 - How to Prompt Opportunities and Challenges of Zer.pdf;/Users/didi/Zotero/storage/I8W7ZDIG/2209.html}
}

@article{dellermannHybridIntelligence2019,
  title = {Hybrid {{Intelligence}}},
  author = {Dellermann, Dominik and Ebel, Philipp and Söllner, Matthias and Leimeister, Jan Marco},
  year = {2019},
  month = oct,
  journal = {Business \& Information Systems Engineering},
  volume = {61},
  number = {5},
  pages = {637--643},
  issn = {1867-0202},
  doi = {10.1007/s12599-019-00595-2},
  urldate = {2023-04-13},
  langid = {english},
  keywords = {Artificial intelligence,Future of work,Human-computer collaboration,Hybrid intelligence,Machine learning,Machines as teammates},
  file = {/Users/didi/Zotero/storage/BYUWYXS4/Dellermann et al. - 2019 - Hybrid Intelligence.pdf}
}

@article{dengRecommenderSystemsBased2022,
  title = {Recommender {{Systems Based}} on {{Graph Embedding Techniques}}: {{A Review}}},
  shorttitle = {Recommender {{Systems Based}} on {{Graph Embedding Techniques}}},
  author = {Deng, Yue},
  year = {2022},
  journal = {IEEE Access},
  volume = {10},
  pages = {51587--51633},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2022.3174197},
  abstract = {As a pivotal tool to alleviate the information overload problem, recommender systems aim to predict user’s preferred items from millions of candidates by analyzing observed user-item relations. As for alleviating the sparsity and cold start problems encountered by recommender systems, researchers generally resort to employing side information or knowledge in recommendation as a strategy for uncovering hidden (indirect) user-item relations, aiming to enrich observed information (or data) for recommendation. However, in the face of the high complexity and large scale of side information and knowledge, this strategy largely relies for efficient implementation on the scalability of recommendation models. Not until after the prevalence of machine learning did graph embedding techniques be a recent concentration, which can efficiently utilize complex and large-scale data. In light of that, equipping recommender systems with graph embedding techniques has been widely studied these years, appearing to outperform conventional recommendation implemented directly based on graph topological analysis (or resolution). As the focus, this article systematically retrospects graph embedding-based recommendation from embedding techniques for bipartite graphs, general graphs and knowledge graphs, and proposes a general design pipeline of that. In addition, after comparing several representative graph embedding-based recommendation models with the most common-used conventional recommendation models on simulations, this article manifests that the conventional models can still overall outperform the graph embedding-based ones in predicting implicit user-item interactions, revealing the comparative weakness of graph embedding-based recommendation in these tasks. To foster future research, this article proposes constructive suggestions on making a trade-off between graph embedding-based recommendation and conventional recommendation in different tasks, and puts forward some open questions.},
  keywords = {Big Data,graph embedding,graph neural networks,Information retrieval,knowledge graphs,machine learning,Machine learning,Pipelines,Predictive models,recommender systems,Recommender systems,Scalability,Task analysis},
  file = {/Users/didi/Zotero/storage/CYVERLZ3/Deng - 2022 - Recommender Systems Based on Graph Embedding Techn.pdf;/Users/didi/Zotero/storage/BUTNKBR5/9772660.html}
}

@misc{EditorialSpecialSection,
  title = {Editorial for the {{Special Section}} on {{Humans}}, {{Algorithms}}, and {{Augmented Intelligence}}: {{The Future}} of {{Work}}, {{Organizations}}, and {{Society}} | {{Information Systems Research}}},
  urldate = {2023-04-03},
  howpublished = {https://pubsonline.informs.org/doi/abs/10.1287/isre.2021.1046}
}

@inproceedings{eggerValueCreationPatterns2022,
  title = {Value {{Creation Patterns}} for {{Industry-relevant Model-based Cyber-Physical Systems}}:},
  shorttitle = {Value {{Creation Patterns}} for {{Industry-relevant Model-based Cyber-Physical Systems}}},
  booktitle = {Proceedings of the 10th {{International Conference}} on {{Model-Driven Engineering}} and {{Software Development}}},
  author = {Egger, Nicolas and Laurenzi, Emanuele},
  year = {2022},
  pages = {364--370},
  publisher = {{SCITEPRESS - Science and Technology Publications}},
  address = {{Online Streaming, --- Select a Country ---}},
  doi = {10.5220/0010984400003119},
  urldate = {2023-04-13},
  abstract = {Cyber-Physical Systems, Enterprise Modelling, Value Proposition.},
  isbn = {978-989-758-550-0},
  langid = {english},
  file = {/Users/didi/Zotero/storage/LPDJ8XX7/Egger and Laurenzi - 2022 - Value Creation Patterns for Industry-relevant Mode.pdf}
}

@incollection{eliasmithSymbolicSubsymbolic2006,
  title = {Symbolic versus {{Subsymbolic}}},
  booktitle = {Encyclopedia of {{Cognitive Science}}},
  author = {Eliasmith, Chris and Bechtel, William},
  year = {2006},
  publisher = {{John Wiley \& Sons, Ltd}},
  doi = {10.1002/0470018860.s00022},
  urldate = {2023-04-07},
  abstract = {There are two competing approaches to computational modeling of cognition: the symbolic approach, based on language-like representations, and the subsymbolic (connectionist) approach, inspired by neuroscience.},
  isbn = {978-0-470-01886-6},
  langid = {english},
  keywords = {computation,connectionism,neural networks,physical symbol systems,representation},
  file = {/Users/didi/Zotero/storage/UD3CYSPJ/0470018860.html}
}

@article{eliazarUniversalityAcceleratingChange2018,
  title = {Universality of Accelerating Change},
  author = {Eliazar, Iddo and Shlesinger, Michael F.},
  year = {2018},
  month = mar,
  journal = {Physica A: Statistical Mechanics and its Applications},
  volume = {494},
  pages = {430--445},
  issn = {0378-4371},
  doi = {10.1016/j.physa.2017.12.021},
  urldate = {2023-04-07},
  abstract = {On large time scales the progress of human technology follows an exponential growth trend that is termed accelerating change. The exponential growth trend is commonly considered to be the amalgamated effect of consecutive technology revolutions – where the progress carried in by each technology revolution follows an S-curve, and where the aging of each technology revolution drives humanity to push for the next technology revolution. Thus, as a collective, mankind is the ‘intelligent designer’ of accelerating change. In this paper we establish that the exponential growth trend –~and only this trend –~emerges universally, on large time scales, from systems that combine together two elements: randomness and amalgamation. Hence, the universal generation of accelerating change can be attained by systems with no ‘intelligent designer’.},
  langid = {english},
  keywords = {Exponential trends,Gompertz law,Invariance,Poisson processes,Universality,Zipf law},
  file = {/Users/didi/Zotero/storage/P2FE587J/Eliazar and Shlesinger - 2018 - Universality of accelerating change.pdf;/Users/didi/Zotero/storage/XCFMN4LY/S0378437117312682.html}
}

@article{elkatatnySelfAdaptiveArtificialIntelligence2018,
  title = {A {{Self-Adaptive Artificial Intelligence Technique}} to {{Predict Oil Pressure Volume Temperature Properties}}},
  author = {Elkatatny, Salaheldin and Moussa, Tamer and Abdulraheem, Abdulazeez and Mahmoud, Mohamed},
  year = {2018},
  month = dec,
  journal = {Energies},
  volume = {11},
  number = {12},
  pages = {3490},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {1996-1073},
  doi = {10.3390/en11123490},
  urldate = {2023-04-13},
  abstract = {Reservoir fluid properties such as bubble point pressure (Pb) and gas solubility (Rs) play a vital role in reservoir management and reservoir simulation. In addition, they affect the design of the production system. Pb and Rs can be obtained from laboratory experiments by taking a sample at the wellhead or from the reservoir under downhole conditions. However, this process is time-consuming and very costly. To overcome these challenges, empirical correlations and artificial intelligence (AI) models can be applied to obtain these properties. The objective of this paper is to introduce new empirical correlations to estimate Pb and Rs based on three input parameters—reservoir temperature and oil and gas gravities. 760 data points were collected from different sources to build new AI models for Pb and Rs. The new empirical correlations were developed by integrating artificial neural network (ANN) with a modified self-adaptive differential evolution algorithm to introduce a hybrid self-adaptive artificial neural network (SaDE-ANN) model. The results obtained confirmed the accuracy of the developed SaDE-ANN models to predict the Pb and Rs of crude oils. This is the first technique that can be used to predict Rs and Pb based on three input parameters only. The developed empirical correlation for Pb predicts the Pb with a correlation coefficient (CC) of 0.99 and an average absolute percentage error (AAPE) of 6\%. The same results were obtained for Rs, where the new empirical correlation predicts the Rs with a coefficient of determination (R2) of 0.99 and an AAPE of less than 6\%. The developed technique will help reservoir and production engineers to better understand and manage reservoirs. No additional or special software is required to run the developed technique.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {artificial intelligence (AI),bubble point pressure correlation,gas solubility correlation,pressure volume temperature (PVT) properties prediction,self-adaptive differential evolution},
  file = {/Users/didi/Zotero/storage/AVNHL8PJ/Elkatatny et al. - 2018 - A Self-Adaptive Artificial Intelligence Technique .pdf}
}

@article{fangMachinesVsHumans2019,
  title = {Machines vs {{Humans}}: {{How Can We Adapt Organizations}} to {{AI}}?},
  shorttitle = {Machines vs {{Humans}}},
  author = {Fang, Christina and Liu, Chengwei and Cowgill, Bo and Denrell, Jerker C. and Puranam, Phanish and Shapira, Zur and Winter, Sidney G.},
  year = {2019},
  month = aug,
  journal = {Academy of Management Proceedings},
  volume = {2019},
  number = {1},
  pages = {12809},
  publisher = {{Academy of Management}},
  issn = {0065-0668},
  doi = {10.5465/AMBPP.2019.12809symposium},
  urldate = {2023-04-03},
  abstract = {Herbert Simon predicted in 1958 that the revolution in computers will force humans to consider our role in a world in which our intellectual power and speed are outstripped by the intelligence of machines. The purpose of this panel symposium is to invite thought leaders in the field of management to share how they consider the role of organizations in a world in which the predictions Simon made are about to be fully realized. In particular, we will focus on how organizations and their members adapt to artificial intelligence (AI) and how organizations learn from machines that are also learning from the (potentially biased) data the organizations generate.},
  keywords = {AOM Annual Meeting Proceedings 2019,AOM Boston 2019}
}

@article{feiArtificialGeneralIntelligence2022,
  title = {Towards Artificial General Intelligence via a Multimodal Foundation Model},
  author = {Fei, Nanyi and Lu, Zhiwu and Gao, Yizhao and Yang, Guoxing and Huo, Yuqi and Wen, Jingyuan and Lu, Haoyu and Song, Ruihua and Gao, Xin and Xiang, Tao and Sun, Hao and Wen, Ji-Rong},
  year = {2022},
  month = jun,
  journal = {Nature Communications},
  volume = {13},
  number = {1},
  pages = {3094},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-30761-2},
  urldate = {2023-04-07},
  abstract = {The fundamental goal of artificial intelligence (AI) is to mimic the core cognitive activities of human. Despite tremendous success in the AI research, most of existing methods have only single-cognitive ability. To overcome this limitation and take a solid step towards artificial general intelligence (AGI), we develop a foundation model pre-trained with huge multimodal data, which can be quickly adapted for various downstream cognitive tasks. To achieve this goal, we propose to pre-train our foundation model by self-supervised learning with weak semantic correlation data crawled from the Internet and show that promising results can be obtained on a wide range of downstream tasks. Particularly, with the developed model-interpretability tools, we demonstrate that strong imagination ability is now possessed by our foundation model. We believe that our work makes a transformative stride towards AGI, from our common practice of “weak or narrow AI” to that of “strong or generalized AI”.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Computational science,Computer science,Learning algorithms},
  file = {/Users/didi/Zotero/storage/GN6RHT5W/Fei et al. - 2022 - Towards artificial general intelligence via a mult.pdf}
}

@misc{garcezNeurosymbolicAI3rd2020,
  title = {Neurosymbolic {{AI}}: {{The}} 3rd {{Wave}}},
  shorttitle = {Neurosymbolic {{AI}}},
  author = {d'Avila Garcez, Artur and Lamb, Luis C.},
  year = {2020},
  month = dec,
  number = {arXiv:2012.05876},
  eprint = {2012.05876},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2012.05876},
  urldate = {2023-04-09},
  abstract = {Current advances in Artificial Intelligence (AI) and Machine Learning (ML) have achieved unprecedented impact across research communities and industry. Nevertheless, concerns about trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many have identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neural-symbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability via symbolic representations for network models. In this paper, we relate recent and early research results in neurosymbolic AI with the objective of identifying the key ingredients of the next wave of AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. The insights provided by 20 years of neural-symbolic computing are shown to shed new light onto the increasingly prominent role of trust, safety, interpretability and accountability of AI. We also identify promising directions and challenges for the next decade of AI research from the perspective of neural-symbolic systems.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,I.2.4,I.2.6},
  file = {/Users/didi/Zotero/storage/UHQUNGQB/Garcez and Lamb - 2020 - Neurosymbolic AI The 3rd Wave.pdf;/Users/didi/Zotero/storage/DTJABX9D/2012.html}
}

@article{garcezNeurosymbolicAI3rd2023,
  title = {Neurosymbolic {{AI}}: The 3rd Wave},
  shorttitle = {Neurosymbolic {{AI}}},
  author = {d’Avila Garcez, Artur and Lamb, Luís C.},
  year = {2023},
  month = mar,
  journal = {Artificial Intelligence Review},
  issn = {1573-7462},
  doi = {10.1007/s10462-023-10448-w},
  urldate = {2023-04-12},
  abstract = {Current advances in Artificial Intelligence (AI) and Machine Learning have achieved unprecedented impact across research communities and industry. Nevertheless, concerns around trust, safety, interpretability and accountability of AI were raised by influential thinkers. Many identified the need for well-founded knowledge representation and reasoning to be integrated with deep learning and for sound explainability. Neurosymbolic computing has been an active area of research for many years seeking to bring together robust learning in neural networks with reasoning and explainability by offering symbolic representations for neural models. In this paper, we relate recent and early research in neurosymbolic AI with the objective of identifying the most important ingredients of neurosymbolic AI systems. We focus on research that integrates in a principled way neural network-based learning with symbolic knowledge representation and logical reasoning. Finally, this review identifies promising directions and challenges for the next decade of AI research from the perspective of neurosymbolic computing, commonsense reasoning and causal explanation.},
  langid = {english},
  keywords = {Cognitive reasoning,Deep learning,Explainable AI,Machine learning,Neurosymbolic AI,Reasoning,Trustworthy AI},
  file = {/Users/didi/Zotero/storage/5II272EN/Garcez and Lamb - 2023 - Neurosymbolic AI the 3rd wave.pdf}
}

@article{goertzelHumanlevelArtificialGeneral2007,
  title = {Human-Level Artificial General Intelligence and the Possibility of a Technological Singularity: {{A}} Reaction to {{Ray Kurzweil}}'s {{The Singularity Is Near}}, and {{McDermott}}'s Critique of {{Kurzweil}}},
  shorttitle = {Human-Level Artificial General Intelligence and the Possibility of a Technological Singularity},
  author = {Goertzel, Ben},
  year = {2007},
  month = dec,
  journal = {Artificial Intelligence},
  series = {Special {{Review Issue}}},
  volume = {171},
  number = {18},
  pages = {1161--1173},
  issn = {0004-3702},
  doi = {10.1016/j.artint.2007.10.011},
  urldate = {2023-04-15},
  abstract = {An analysis of Ray Kurzweil's recent book The Singularity Is Near is given, along with Drew McDermott's recent critique. The conclusion is that Kurzweil does an excellent job of fleshing out one particular plausible scenario regarding the future of AI, in which human-level AI first arrives via human-brain emulation. McDermott's arguments against the notion of Singularity via iteratively self-improving AI, as described by Kurzweil, are considered and found wanting. However, it is pointed out that the scenario focused on by Kurzweil is not the only plausible one; and an alternative is discussed, in which human-level AI arrives first via non-human-like AI's operating virtual worlds.},
  langid = {english},
  keywords = {AGI,Language acquisition,narrow AI,Self-modifying software,Singularity virtual worlds,Strong AI},
  file = {/Users/didi/Zotero/storage/EDCFRYYD/Goertzel - 2007 - Human-level artificial general intelligence and th.pdf;/Users/didi/Zotero/storage/RA3EYV7D/S0004370207001464.html}
}

@article{guptaArticulatingRoleArtificial2021,
  title = {Articulating the {{Role}} of {{Artificial Intelligence}} in {{Collective Intelligence}}: {{A Transactive Systems Framework}}},
  shorttitle = {Articulating the {{Role}} of {{Artificial Intelligence}} in {{Collective Intelligence}}},
  author = {Gupta, Pranav and Woolley, Anita Williams},
  year = {2021},
  month = sep,
  journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
  volume = {65},
  number = {1},
  pages = {670--674},
  publisher = {{SAGE Publications Inc}},
  issn = {2169-5067},
  doi = {10.1177/1071181321651354c},
  urldate = {2023-04-04},
  abstract = {Human society faces increasingly complex problems that require coordinated collective action. Artificial intelligence (AI) holds the potential to bring together the knowledge and associated action needed to find solutions at scale. In order to unleash the potential of human and AI systems, we need to understand the core functions of collective intelligence. To this end, we describe a socio-cognitive architecture that conceptualizes how boundedly rational individuals coordinate their cognitive resources and diverse goals to accomplish joint action. Our transactive systems framework articulates the inter-member processes underlying the emergence of collective memory, attention, and reasoning, which are fundamental to intelligence in any system. Much like the cognitive architectures that have guided the development of artificial intelligence, our transactive systems framework holds the potential to be formalized in computational terms to deepen our understanding of collective intelligence and pinpoint roles that AI can play in enhancing it.},
  langid = {english},
  file = {/Users/didi/Zotero/storage/K54XTM58/Gupta and Woolley - 2021 - Articulating the Role of Artificial Intelligence i.pdf}
}

@article{harmelenBoxologyDesignPatterns2019,
  title = {A {{Boxology}} of {{Design Patterns}} for {{Hybrid Learning}} and {{Reasoning Systems}}},
  author = {van Harmelen, Frank and ten Teije, Annette},
  year = {2019},
  month = jan,
  journal = {Journal of Web Engineering},
  volume = {18},
  number = {1},
  pages = {97--124},
  publisher = {{River Publishers}},
  issn = {1540-9589, 1544-5976},
  doi = {10.13052/jwe1540-9589.18133},
  urldate = {2023-04-07},
  abstract = {A Boxology of Design Patterns for Hybrid Learning and Reasoning Systems},
  file = {/Users/didi/Zotero/storage/46LGR6Z6/Harmelen and Teije - 2019 - A Boxology of Design Patterns for Hybrid Learning .pdf}
}

@article{hauptmanAdaptOvercomePerceptions2023,
  title = {Adapt and Overcome: {{Perceptions}} of Adaptive Autonomous Agents for Human-{{AI}} Teaming},
  shorttitle = {Adapt and Overcome},
  author = {Hauptman, Allyson I. and Schelble, Beau G. and McNeese, Nathan J. and Madathil, Kapil Chalil},
  year = {2023},
  month = jan,
  journal = {Computers in Human Behavior},
  volume = {138},
  pages = {107451},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2022.107451},
  urldate = {2023-04-17},
  abstract = {Rapid advances in AI technologies have caused teams to explore the use of AI agents as full, active members of the team. The complex environments that teams occupy require human team members to constantly adapt their behaviors, and thus the ability of AI teammates to similarly adapt to changing situations significantly enhances the team’s chances to succeed. In order to design such agents, it is important that we understand not only how to identify the amount of autonomous control AI agents have over their decisions, but also how changes to this control cognitively affects the rest of the team. Professional organizations often break their work cycles into phases that set limits on the team members’ actions, and we propose that a similar process could be used to define the autonomy levels of AI teammates. Cyber incident response is an ideal context for this proposal, as we were able to use incident response phases to explore how a team’s work cycle could guide an AI agent’s changing level of autonomy. Using a mixed methods approach, we recruited 103 participants to complete a factorial survey containing ten contextual vignettes focused on an AI teammate’s level of autonomy in incident response contexts, and from these participants we conducted twenty-two follow-on qualitative interviews that further explored how the participants felt an AI agent’s adaptive capabilities would affect team performance and cohesiveness. Our results showed that work cycles can be used to assign autonomy levels to adaptive AI agents based upon the degree of formal processes and predictability of the team’s tasks during the cycle, and that dynamic, human-like adaptation methods are vital to effective human-AI teams. This research provides significant contributions to the HCI community by proposing design recommendations for the development of adaptive autonomous teammates that both enhance Human-AI teams’ productivity and promote positive team dynamics.},
  langid = {english},
  keywords = {Adaptive autonomy,Autonomous agents,Computer security,Cyber security,Human-autonomy teaming,Incident response},
  file = {/Users/didi/Zotero/storage/YGA9X587/Hauptman et al. - 2023 - Adapt and overcome Perceptions of adaptive autono.pdf;/Users/didi/Zotero/storage/8EYNN5NB/S0747563222002722.html}
}

@article{hayes-rothArchitectureAdaptiveIntelligent1995,
  title = {An Architecture for Adaptive Intelligent Systems},
  author = {{Hayes-Roth}, Barbara},
  year = {1995},
  month = jan,
  journal = {Artificial Intelligence},
  volume = {72},
  number = {1},
  pages = {329--365},
  issn = {0004-3702},
  doi = {10.1016/0004-3702(94)00004-K},
  urldate = {2023-04-17},
  abstract = {Our goal is to understand and build comprehensive agents that function effectively in challenging niches. In particular, we identify a class of niches to be occupied by “adaptive intelligent systems (AISs)”. In contrast with niches occupied by typical AI agents, AIS niches present situations that vary dynamically along several key dimensions: different combinations of required tasks, different configurations of available resources, contextual conditions ranging from benign to stressful, and different performance criteria. We present a small class hierarchy of AIS niches that exhibit these dimensions of variability and describe a particular AIS niche, ICU (intensive care unit) patient monitoring, which we use for illustration throughout the paper. To function effectively throughout the range of situations presented by an AIS niche, an agent must be highly adaptive. In contrast with the rather Stereotypie behavior of typical AI agents, an AIS must adapt several key aspects of its behavior to its dynamic situation: its perceptual strategy, its control mode, its choices of reasoning tasks to perform, its choices of reasoning methods for performing chosen tasks; and its meta-control strategy for global coordination of all its behavior. We have designed and implemented an agent architecture that supports all of these different kinds of adaptation by exploiting a single underlying theoretical concept: An agent dynamically constructs explicit control plans to guide its choices among situation-triggered behaviors. The architecture has been used to build experimental agents for several AIS niches. We illustrate the architecture and its support for adaptation with examples from Guardian, an experimental agent for ICU monitoring.},
  langid = {english},
  file = {/Users/didi/Zotero/storage/X27EQU4T/Hayes-Roth - 1995 - An architecture for adaptive intelligent systems.pdf;/Users/didi/Zotero/storage/FUHI5U43/000437029400004K.html}
}

@misc{HHAIConferencesHHAI2023,
  title = {{{HHAI Conferences}} – {{HHAI2023}}},
  urldate = {2023-04-15},
  langid = {american},
  file = {/Users/didi/Zotero/storage/BBYZFD53/hhai-conference.org.html}
}

@article{hoArtificialIntelligenceFirm2022,
  title = {Artificial {{Intelligence}} and {{Firm Performance}}: {{Does Machine Intelligence Shield Firms}} from {{Risks}}?},
  shorttitle = {Artificial {{Intelligence}} and {{Firm Performance}}},
  author = {Ho, Linh Tu and Gan, Christopher and Jin, Shan and Le, Bryan},
  year = {2022},
  month = jul,
  journal = {Journal of Risk and Financial Management},
  volume = {15},
  number = {7},
  pages = {302},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {1911-8074},
  doi = {10.3390/jrfm15070302},
  urldate = {2023-04-06},
  abstract = {We estimate and compare the impact of the coronavirus pandemic (COVID-19) on the performance of Artificial Intelligence (AI) and conventional listed firms using stock market indices. The single-group and multiple-group Interrupted Time-Series Analyses (ITSA) with panel data were used with four interventions: when the news of COVID-19 spread and the pandemic entered the first, second, third, and fourth months (24 February 2020, 23 March 2020, 20 April 2020, and 18 May 2020, respectively). The results show that the negative impact of COVID-19 on the AI stock market was less severe than on the conventional stock market in the first month of the pandemic. The performance of the AI stock market recovered quicker than the conventional stock market when the pandemic went into its third month. The results suggest that the AI stocks were more resilient than conventional stocks when the financial market was exposed to uncertainty caused by the COVID-19 pandemic. The deployment of AI in firms serves as a resilient, crucial driver for sustainable performance in challenging environments. Observing the performance of AI-adopted firms is an interesting direction for technical and fundamental analysts. Investors and portfolio managers should consider an AI market index to minimize risk or invest in stocks of AI-adopted listed firms to maximize excess returns.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {AI,artificial intelligence,ITSA,pandemic,risk management,stock performance},
  file = {/Users/didi/Zotero/storage/77MLQWAN/Ho et al. - 2022 - Artificial Intelligence and Firm Performance Does.pdf}
}

@article{hochreiterBroadAI2022,
  title = {Toward a Broad {{AI}}},
  author = {Hochreiter, Sepp},
  year = {2022},
  month = mar,
  journal = {Communications of the ACM},
  volume = {65},
  number = {4},
  pages = {56--57},
  issn = {0001-0782},
  doi = {10.1145/3512715},
  urldate = {2023-04-09},
  file = {/Users/didi/Zotero/storage/2TIMQULA/Hochreiter - 2022 - Toward a broad AI.pdf}
}

@misc{HowRandomReview,
  title = {How Random Is the Review Outcome? {{A}} Systematic Study of the Impact of External Factors on {{eLife}} Peer Review | {{bioRxiv}}},
  urldate = {2023-04-17},
  howpublished = {https://www.biorxiv.org/content/10.1101/2023.01.04.522708v1.abstract}
}

@misc{HumanrobotMutualAdaptation,
  title = {Human-Robot Mutual Adaptation in Collaborative Tasks: {{Models}} and Experiments - {{Stefanos Nikolaidis}}, {{David Hsu}}, {{Siddhartha Srinivasa}}, 2017},
  urldate = {2023-04-17},
  howpublished = {https://journals.sagepub.com/doi/10.1177/0278364917690593}
}

@misc{HumansLoopDesign,
  title = {Humans in the {{Loop}}: {{The Design}} of {{Interactive AI Systems}}},
  shorttitle = {Humans in the {{Loop}}},
  journal = {Stanford HAI},
  urldate = {2023-04-05},
  howpublished = {https://hai.stanford.edu/news/humans-loop-design-interactive-ai-systems},
  langid = {english},
  file = {/Users/didi/Zotero/storage/MFNNW42H/humans-loop-design-interactive-ai-systems.html}
}

@book{hurwitzAugmentedIntelligenceBusiness2019,
  title = {Augmented {{Intelligence}}: {{The Business Power}} of {{Human}}–{{Machine Collaboration}}},
  shorttitle = {Augmented {{Intelligence}}},
  author = {Hurwitz, Judith and Morris, Henry and Sidner, Candace and Kirsch, Daniel},
  year = {2019},
  month = dec,
  publisher = {{Auerbach Publications}},
  address = {{New York}},
  doi = {10.1201/9780429196645},
  abstract = {The AI revolution is moving at a breakneck speed. Organizations are beginning to invest in innovative ways to monetize their data through the use of artificial intelligence. Businesses need to understand the reality of AI. To be successful, it is imperative that organizations understand that augmented intelligence is the secret to success. Augmented Intelligence: The Business Power of Human–Machine Collaboration is about the process of combining human and machine intelligence. This book provides business leaders and AI data experts with an understanding of the value of augmented intelligence and its ability to help win competitive markets. This book focuses on the requirement to clearly manage the foundational data used for augmented intelligence. It focuses on the risks of improper data use and delves into the ethics and governance of data in the era of augmented intelligence. In this book, we explore the difference between weak augmentation that is based on automating well understood processes and strong augmentation that is designed to rethink business processes through the inclusion of data, AI and machine learning. What experts are saying about Augmented Intelligence "The book you are about to read is of great importance because we increasingly rely on machine learning and AI. Therefore, it is critical that we understand the ability to create an environment in which businesses can have the tools to understand data from a holistic perspective. What is imperative is to be able to make better decisions based on an understanding of the behavior and thinking of our customers so that we can take the best next action. This book provides a clear understanding of the impact of augmented intelligence on both society and business."—Tsvi Gal, Managing Director, Enterprise Technology and Services, Morgan Stanley "Our mission has always been to help clients apply AI to better predict and shape future outcomes, empower higher value work, and automate how work gets done. I have always said, ’AI will not replace managers, but managers who use AI will replace managers who don't.’ This book delves into the real value that AI promises, to augment existing human intelligence, and in the process, dispels some of the myths around AI and its intended purpose."—Rob Thomas, General Manager, Data and AI, IBM},
  isbn = {978-0-429-19664-5}
}

@inproceedings{ilkouSymbolicVsSubsymbolic2020,
  title = {Symbolic {{Vs Sub-symbolic AI Methods}}: {{Friends}} or {{Enemies}}?},
  shorttitle = {Symbolic {{Vs Sub-symbolic AI Methods}}},
  booktitle = {International {{Conference}} on {{Information}} and {{Knowledge Management}}},
  author = {Ilkou, Eleni and Koutraki, Maria},
  year = {2020},
  urldate = {2023-04-07},
  abstract = {There is a long and unresolved debate between the symbolic and sub-symbolic methods. However, in recent years, there is a push towards in-between methods. In this work, we provide a comprehensive overview of the symbolic, sub-symbolic and in-between approaches focused in the domain of knowledge graphs, namely, schema representation, schema matching, knowledge graph completion, link prediction, entity resolution, entity classification and triple classification. We critically present key characteristics, advantages and disadvantages of the main algorithms in each domain, and review the use of these methods in knowledge graph related applications.},
  file = {/Users/didi/Zotero/storage/7BD565BC/Ilkou and Koutraki - 2020 - Symbolic Vs Sub-symbolic AI Methods Friends or En.pdf}
}

@misc{IntroducingAgentsHaystack,
  title = {Introducing {{Agents}} in {{Haystack}}: {{Make LLMs}} Resolve Complex Tasks},
  shorttitle = {Introducing {{Agents}} in {{Haystack}}},
  journal = {Haystack},
  urldate = {2023-04-06},
  abstract = {LLMs can now make use of the right tools to resolve complex queries and tasks},
  howpublished = {https://haystack.deepset.ai/blog/introducing-haystack-agents/},
  langid = {english}
}

@article{jarrahiArtificialIntelligenceFuture2018,
  title = {Artificial Intelligence and the Future of Work: {{Human-AI}} Symbiosis in Organizational Decision Making},
  shorttitle = {Artificial Intelligence and the Future of Work},
  author = {Jarrahi, Mohammad Hossein},
  year = {2018},
  month = jul,
  journal = {Business Horizons},
  volume = {61},
  number = {4},
  pages = {577--586},
  issn = {0007-6813},
  doi = {10.1016/j.bushor.2018.03.007},
  urldate = {2023-04-04},
  abstract = {Artificial intelligence (AI) has penetrated many organizational processes, resulting in a growing fear that smart machines will soon replace many humans in decision making. To provide a more proactive and pragmatic perspective, this article highlights the complementarity of humans and AI and examines how each can bring their own strength in organizational decision-making processes typically characterized by uncertainty, complexity, and equivocality. With a greater computational information processing capacity and an analytical approach, AI can extend humans’ cognition when addressing complexity, whereas humans can still offer a more holistic, intuitive approach in dealing with uncertainty and equivocality in organizational decision making. This premise mirrors the idea of intelligence augmentation, which states that AI systems should be designed with the intention of augmenting, not replacing, human contributions.},
  langid = {english},
  keywords = {Analytical and intuitive decision making,Artificial intelligence,Human augmentation,Human-machine symbiosis,Organizational decision making},
  file = {/Users/didi/Zotero/storage/KQJCIT22/Jarrahi - 2018 - Artificial intelligence and the future of work Hu.pdf;/Users/didi/Zotero/storage/5XU7VII5/S0007681318300387.html}
}

@article{jiSurveyHallucinationNatural2023,
  title = {Survey of {{Hallucination}} in {{Natural Language Generation}}},
  author = {Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  year = {2023},
  month = mar,
  journal = {ACM Computing Surveys},
  volume = {55},
  number = {12},
  pages = {248:1--248:38},
  issn = {0360-0300},
  doi = {10.1145/3571730},
  urldate = {2023-04-20},
  abstract = {Natural Language Generation (NLG) has improved exponentially in recent years thanks to the development of sequence-to-sequence deep learning technologies such as Transformer-based language models. This advancement has led to more fluent and coherent NLG, leading to improved development in downstream tasks such as abstractive summarization, dialogue generation, and data-to-text generation. However, it is also apparent that deep learning based generation is prone to hallucinate unintended text, which degrades the system performance and fails to meet user expectations in many real-world scenarios. To address this issue, many studies have been presented in measuring and mitigating hallucinated texts, but these have never been reviewed in a comprehensive manner before. In this survey, we thus provide a broad overview of the research progress and challenges in the hallucination problem in NLG. The survey is organized into two parts: (1) a general overview of metrics, mitigation methods, and future directions, and (2) an overview of task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, and machine translation. This survey serves to facilitate collaborative efforts among researchers in tackling the challenge of hallucinated texts in NLG.},
  keywords = {consistency in NLG,extrinsic hallucination,factuality in NLG,faithfulness in NLG,Hallucination,intrinsic hallucination},
  file = {/Users/didi/Zotero/storage/V5HRV9R6/Ji et al. - 2023 - Survey of Hallucination in Natural Language Genera.pdf}
}

@article{kabudiAIenabledAdaptiveLearning2021,
  title = {{{AI-enabled}} Adaptive Learning Systems: {{A}} Systematic Mapping of the Literature},
  shorttitle = {{{AI-enabled}} Adaptive Learning Systems},
  author = {Kabudi, Tumaini and Pappas, Ilias and Olsen, Dag Håkon},
  year = {2021},
  month = jan,
  journal = {Computers and Education: Artificial Intelligence},
  volume = {2},
  pages = {100017},
  issn = {2666-920X},
  doi = {10.1016/j.caeai.2021.100017},
  urldate = {2023-04-13},
  abstract = {Mobile internet, cloud computing, big data technologies, and significant breakthroughs in Artificial Intelligence (AI) have all transformed education. In recent years, there has been an emergence of more advanced AI-enabled learning systems, which are gaining traction due to their ability to deliver learning content and adapt to the individual needs of students. Yet, even though these contemporary learning systems are useful educational platforms that meet students’ needs, there is still a low number of implemented systems designed to address the concerns and problems faced by many students. Based on this perspective, a systematic mapping of the literature on AI-enabled adaptive learning systems was performed in this work. A total of 147 studies published between 2014 and 2020 were analysed. The major findings and contributions of this paper include the identification of the types of AI-enabled learning interventions used, a visualisation of the co-occurrences of authors associated with major research themes in AI-enabled learning systems and a review of common analytical methods and related techniques utilised in such learning systems. This mapping can serve as a guide for future studies on how to better design AI-enabled learning systems to solve specific learning problems and improve users’ learning experiences.},
  langid = {english},
  keywords = {Adaptive learning systems,AI,AI-Enabled learning systems},
  file = {/Users/didi/Zotero/storage/PBLWD726/Kabudi et al. - 2021 - AI-enabled adaptive learning systems A systematic.pdf}
}

@article{kambhampatiChallengesHumanAwareAI2020,
  title = {Challenges of {{Human-Aware AI Systems}}: {{AAAI Presidential Address}}},
  shorttitle = {Challenges of {{Human-Aware AI Systems}}},
  author = {Kambhampati, Subbarao},
  year = {2020},
  month = sep,
  journal = {AI Magazine},
  volume = {41},
  number = {3},
  pages = {3--17},
  issn = {2371-9621},
  doi = {10.1609/aimag.v41i3.5257},
  urldate = {2023-04-02},
  abstract = {From its inception, artificial intelligence (AI) has had a rather ambivalent relationship to humans — swinging between their augmentation and their replacement. Now, as AI technologies enter our everyday lives at an ever-increasing pace, there is a greater need for AI systems to work synergistically with humans. To do this effectively, AI systems must pay more attention to aspects of intelligence that help humans work with each other — including social intelligence. I will discuss the research challenges in designing such human-aware AI systems, including modeling the mental states of humans-in-the-loop and recognizing their desires and intentions, providing proactive support, exhibiting explicable behavior, giving cogent explanations on demand, and engendering trust. I will survey the progress made so far on these challenges, and highlight some promising directions. I will also touch on the additional ethical quandaries that such systems pose. I will end by arguing that the quest for human-aware AI systems broadens the scope of AI enterprise; necessitates and facilitates true interdisciplinary collaborations; and can go a long way toward increasing public acceptance of AI technologies.},
  copyright = {Copyright (c) 2020 AI Magazine},
  langid = {english},
  file = {/Users/didi/Zotero/storage/JJIUZL2R/Kambhampati - 2020 - Challenges of Human-Aware AI Systems AAAI Preside.pdf}
}

@misc{karpasMRKLSystemsModular2022,
  title = {{{MRKL Systems}}: {{A}} Modular, Neuro-Symbolic Architecture That Combines Large Language Models, External Knowledge Sources and Discrete Reasoning},
  shorttitle = {{{MRKL Systems}}},
  author = {Karpas, Ehud and Abend, Omri and Belinkov, Yonatan and Lenz, Barak and Lieber, Opher and Ratner, Nir and Shoham, Yoav and Bata, Hofit and Levine, Yoav and {Leyton-Brown}, Kevin and Muhlgay, Dor and Rozen, Noam and Schwartz, Erez and Shachaf, Gal and {Shalev-Shwartz}, Shai and Shashua, Amnon and Tenenholtz, Moshe},
  year = {2022},
  month = may,
  number = {arXiv:2205.00445},
  eprint = {2205.00445},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2205.00445},
  urldate = {2023-04-05},
  abstract = {Huge language models (LMs) have ushered in a new era for AI, serving as a gateway to natural-language-based knowledge tasks. Although an essential element of modern AI, LMs are also inherently limited in a number of ways. We discuss these limitations and how they can be avoided by adopting a systems approach. Conceptualizing the challenge as one that involves knowledge and reasoning in addition to linguistic processing, we define a flexible architecture with multiple neural models, complemented by discrete knowledge and reasoning modules. We describe this neuro-symbolic architecture, dubbed the Modular Reasoning, Knowledge and Language (MRKL, pronounced "miracle") system, some of the technical challenges in implementing it, and Jurassic-X, AI21 Labs' MRKL system implementation.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/didi/Zotero/storage/GGWSRKAL/Karpas et al. - 2022 - MRKL Systems A modular, neuro-symbolic architectu.pdf;/Users/didi/Zotero/storage/5ACJ7PL3/2205.html}
}

@article{khanAdvancementsMicroprocessorArchitecture2021,
  title = {Advancements in {{Microprocessor Architecture}} for {{Ubiquitous AI}}—{{An Overview}} on {{History}}, {{Evolution}}, and {{Upcoming Challenges}} in {{AI Implementation}}},
  author = {Khan, Fatima Hameed and Pasha, Muhammad Adeel and Masud, Shahid},
  year = {2021},
  month = jun,
  journal = {Micromachines},
  volume = {12},
  number = {6},
  pages = {665},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2072-666X},
  doi = {10.3390/mi12060665},
  urldate = {2023-04-12},
  abstract = {Artificial intelligence (AI) has successfully made its way into contemporary industrial sectors such as automobiles, defense, industrial automation 4.0, healthcare technologies, agriculture, and many other domains because of its ability to act autonomously without continuous human interventions. However, this capability requires processing huge amounts of learning data to extract useful information in real time. The buzz around AI is not new, as this term has been widely known for the past half century. In the 1960s, scientists began to think about machines acting more like humans, which resulted in the development of the first natural language processing computers. It laid the foundation of AI, but there were only a handful of applications until the 1990s due to limitations in processing speed, memory, and computational power available. Since the 1990s, advancements in computer architecture and memory organization have enabled microprocessors to deliver much higher performance. Simultaneously, improvements in the understanding and mathematical representation of AI gave birth to its subset, referred to as machine learning (ML). ML includes different algorithms for independent learning, and the most promising ones are based on brain-inspired techniques classified as artificial neural networks (ANNs). ANNs have subsequently evolved to have deeper and larger structures and are often characterized as deep neural networks (DNN) and convolution neural networks (CNN). In tandem with the emergence of multicore processors, ML techniques started to be embedded in a range of scenarios and applications. Recently, application-specific instruction-set architecture for AI applications has also been supported in different microprocessors. Thus, continuous improvement in microprocessor capabilities has reached a stage where it is now possible to implement complex real-time intelligent applications like computer vision, object identification, speech recognition, data security, spectrum sensing, etc. This paper presents an overview on the evolution of AI and how the increasing capabilities of microprocessors have fueled the adoption of AI in a plethora of application domains. The paper also discusses the upcoming trends in microprocessor architectures and how they will further propel the assimilation of AI in our daily lives.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {application-specific integrated circuits,artificial intelligence,automation,instruction set architecture,intelligent systems,machine learning,microprocessors,multicores,real-time processing},
  file = {/Users/didi/Zotero/storage/EQP5ML5M/Khan et al. - 2021 - Advancements in Microprocessor Architecture for Ub.pdf}
}

@article{kortelingHumanArtificialIntelligence2021,
  title = {Human- versus {{Artificial Intelligence}}},
  author = {Korteling, J. E. (Hans). and {van de Boer-Visschedijk}, G. C. and Blankendaal, R. A. M. and Boonekamp, R. C. and Eikelboom, A. R.},
  year = {2021},
  journal = {Frontiers in Artificial Intelligence},
  volume = {4},
  issn = {2624-8212},
  doi = {10.3389/frai.2021.622364},
  urldate = {2023-04-03},
  abstract = {AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and “collaborate” with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI “partners” with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying ‘psychological’ mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed.},
  file = {/Users/didi/Zotero/storage/B4MFW24Z/Korteling et al. - 2021 - Human- versus Artificial Intelligence.pdf}
}

@incollection{kurzweilSingularity2014,
  title = {The {{Singularity}} Is {{Near}}},
  booktitle = {Ethics and {{Emerging Technologies}}},
  author = {Kurzweil, Ray},
  editor = {Sandler, Ronald L.},
  year = {2014},
  pages = {393--406},
  publisher = {{Palgrave Macmillan UK}},
  address = {{London}},
  doi = {10.1057/9781137349088_26},
  urldate = {2023-04-15},
  abstract = {In this chapter, Ray Kurzweil presents and defends his view that we will reach a technological singularity in the next few decades, which he defines as a “period during which the pace of technological change will be so rapid, its impact so deep, that human life will be irreversibly transformed.” Kurwzweil argues that the pace of technological change, particularly with respect to information technologies, is exponential, and that we are near the “knee” of the exponential curve (i.e. the point at which the curve changes from largely horizontal to largely vertical). Kurzweil predicts that a core feature of the singularity will be the merging of biological and machine intelligence, such that the majority of “human” intelligence will become non-biological, and the merging of virtual and physical reality. Kurzweil considers this the next step in human-machine co-evolution.},
  isbn = {978-1-137-34908-8},
  langid = {english},
  keywords = {Event Horizon,Exponential Growth,Human Intelligence,Machine Intelligence,narrow AI,Virtual Reality}
}

@inproceedings{liaoUserTrustRecommendation2022,
  title = {User {{Trust}} in {{Recommendation Systems}}: {{A}} Comparison of {{Content-Based}}, {{Collaborative}} and {{Demographic Filtering}}},
  shorttitle = {User {{Trust}} in {{Recommendation Systems}}},
  booktitle = {Proceedings of the 2022 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Liao, Mengqi and Sundar, S. Shyam and B. Walther, Joseph},
  year = {2022},
  month = apr,
  series = {{{CHI}} '22},
  pages = {1--14},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3491102.3501936},
  urldate = {2023-04-17},
  abstract = {Three of the most common approaches used in recommender systems are content-based filtering (matching users’ preferences with products’ characteristics), collaborative filtering (matching users with similar preferences), and demographic filtering (catering to users based on demographic characteristics). Do users’ intuitions lead them to trust one of these approaches over others, independent of the actual operations of these different systems? Does their faith in one type or another depend on the quality of the recommendation, rather than how the recommendation appears to have been derived? We conducted an empirical study with a prototype of a movie recommender system to find out. A 3 (Ostensible Recommender Type: Content vs. Collaborative vs. Demographic Filtering) x 2 (Recommendation Quality: Good vs. Bad) experiment (N=226) investigated how users evaluate systems and attribute responsibility for the recommendations they receive. We found that users trust systems that use collaborative filtering more, regardless of the system's performance. They think that they themselves are responsible for good recommendations but that the system is responsible for bad recommendations (reflecting a self-serving bias). Theoretical insights, design implications and practical solutions for the cold start problem are discussed.},
  isbn = {978-1-4503-9157-3},
  keywords = {Empirical study that tells us about how people use a system,Personalization,User Experience Design}
}

@inproceedings{liuWhatMakesGood2022,
  title = {What {{Makes Good In-Context Examples}} for {{GPT-3}}?},
  booktitle = {Proceedings of {{Deep Learning Inside Out}} ({{DeeLIO}} 2022): {{The}} 3rd {{Workshop}} on {{Knowledge Extraction}} and {{Integration}} for {{Deep Learning Architectures}}},
  author = {Liu, Jiachang and Shen, Dinghan and Zhang, Yizhe and Dolan, Bill and Carin, Lawrence and Chen, Weizhu},
  year = {2022},
  month = may,
  pages = {100--114},
  publisher = {{Association for Computational Linguistics}},
  address = {{Dublin, Ireland and Online}},
  doi = {10.18653/v1/2022.deelio-1.10},
  urldate = {2023-04-26},
  abstract = {GPT-3 has attracted lots of attention due to its superior performance across a wide range of NLP tasks, especially with its in-context learning abilities. Despite its success, we found that the empirical results of GPT-3 depend heavily on the choice of in-context examples. In this work, we investigate whether there are more effective strategies for judiciously selecting in-context examples (relative to random sampling) that better leverage GPT-3's in-context learning capabilities.Inspired by the recent success of leveraging a retrieval module to augment neural networks, we propose to retrieve examples that are semantically-similar to a test query sample to formulate its corresponding prompt. Intuitively, the examples selected with such a strategy may serve as more informative inputs to unleash GPT-3's power of text generation. We evaluate the proposed approach on several natural language understanding and generation benchmarks, where the retrieval-based prompt selection approach consistently outperforms the random selection baseline. Moreover, it is observed that the sentence encoders fine-tuned on task-related datasets yield even more helpful retrieval results. Notably, significant gains are observed on tasks such as table-to-text generation (44.3\% on the ToTTo dataset) and open-domain question answering (45.5\% on the NQ dataset).},
  file = {/Users/didi/Zotero/storage/29X5BJZS/Liu et al. - 2022 - What Makes Good In-Context Examples for GPT-3.pdf}
}

@misc{loftinImpossibilityLearningCooperate2022,
  title = {On the {{Impossibility}} of {{Learning}} to {{Cooperate}} with {{Adaptive Partner Strategies}} in {{Repeated Games}}},
  author = {Loftin, Robert and Oliehoek, Frans A.},
  year = {2022},
  month = nov,
  number = {arXiv:2206.10614},
  eprint = {2206.10614},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2206.10614},
  urldate = {2023-04-15},
  abstract = {Learning to cooperate with other agents is challenging when those agents also possess the ability to adapt to our own behavior. Practical and theoretical approaches to learning in cooperative settings typically assume that other agents' behaviors are stationary, or else make very specific assumptions about other agents' learning processes. The goal of this work is to understand whether we can reliably learn to cooperate with other agents without such restrictive assumptions, which are unlikely to hold in real-world applications. Our main contribution is a set of impossibility results, which show that no learning algorithm can reliably learn to cooperate with all possible adaptive partners in a repeated matrix game, even if that partner is guaranteed to cooperate with some stationary strategy. Motivated by these results, we then discuss potential alternative assumptions which capture the idea that an adaptive partner will only adapt rationally to our behavior.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Science and Game Theory,Computer Science - Machine Learning,Computer Science - Multiagent Systems,I.2.6},
  file = {/Users/didi/Zotero/storage/GJDAAUSH/Loftin and Oliehoek - 2022 - On the Impossibility of Learning to Cooperate with.pdf;/Users/didi/Zotero/storage/Q39ZZ8SF/2206.html}
}

@article{luDatadrivenDecisionSupport2020,
  title = {Data-Driven Decision Support under Concept Drift in Streamed Big Data},
  author = {Lu, Jie and Liu, Anjin and Song, Yiliao and Zhang, Guangquan},
  year = {2020},
  month = apr,
  journal = {Complex \& Intelligent Systems},
  volume = {6},
  number = {1},
  pages = {157--163},
  issn = {2198-6053},
  doi = {10.1007/s40747-019-00124-4},
  urldate = {2023-04-22},
  abstract = {Data-driven decision-making (\$\$\textbackslash mathrm \{D\^3\}\$\$M) is often confronted by the problem of uncertainty or unknown dynamics in streaming data. To provide real-time accurate decision solutions, the systems have to promptly address changes in data distribution in streaming data—a phenomenon known as concept drift. Past data patterns may not be relevant to new data when a data stream experiences significant drift, thus to continue using models based on past data will lead to poor prediction and poor decision outcomes. This position paper discusses the basic framework and prevailing techniques in streaming type big data and concept drift for \$\$\textbackslash mathrm \{D\^3\}\$\$M. The study first establishes a technical framework for real-time \$\$\textbackslash mathrm \{D\^3\}\$\$M under concept drift and details the characteristics of high-volume streaming data. The main methodologies and approaches for detecting concept drift and supporting \$\$\textbackslash mathrm \{D\^3\}\$\$M are highlighted and presented. Lastly, further research directions, related methods and procedures for using streaming data to support decision-making in concept drift environments are identified. We hope the observations in this paper could support researchers and professionals to better understand the fundamentals and research directions of \$\$\textbackslash mathrm \{D\^3\}\$\$M in streamed big data environments.},
  langid = {english},
  keywords = {Big data,Concept drift,Data-driven decision support,Streaming data},
  file = {/Users/didi/Zotero/storage/RZ77D6BS/Lu et al. - 2020 - Data-driven decision support under concept drift i.pdf}
}

@article{MachinesAugmentingEntrepreneurs2022,
  title = {Machines Augmenting Entrepreneurs: {{Opportunities}} (and Threats) at the {{Nexus}} of Artificial Intelligence and Entrepreneurship},
  shorttitle = {Machines Augmenting Entrepreneurs},
  year = {2022},
  month = jul,
  journal = {Journal of Business Venturing},
  volume = {37},
  number = {4},
  pages = {106227},
  publisher = {{Elsevier}},
  issn = {0883-9026},
  doi = {10.1016/j.jbusvent.2022.106227},
  urldate = {2023-04-03},
  abstract = {Artificial intelligence (AI) refers to machines that are trained to perform tasks associated with human intelligence, interpret external data, learn f…},
  langid = {english},
  file = {/Users/didi/Zotero/storage/FBIVEGJF/2022 - Machines augmenting entrepreneurs Opportunities (.pdf;/Users/didi/Zotero/storage/AEIV9UYJ/S0883902622000398.html}
}

@article{madeiraDesigningReinforcementLearningBased2006,
  title = {Designing a {{Reinforcement Learning-Based Adaptive AI}} for {{Large-Scale Strategy Games}}},
  author = {Madeira, Charles and Corruble, Vincent and Ramalho, Geber},
  year = {2006},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
  volume = {2},
  number = {1},
  pages = {121--123},
  issn = {2334-0924},
  doi = {10.1609/aiide.v2i1.18759},
  urldate = {2023-04-13},
  abstract = {This paper investigates the challenges posed by the application of reinforcement learning to large-scale strategy games. In this context, we present steps and techniques which synthesize new ideas with state-of-the-art techniques from several areas of machine learning in a novel integrated learning approach for this kind of games. The performance of the approach is demonstrated on the task of learning valuable game strategies for a commercial wargame.},
  copyright = {Copyright (c) 2021 Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
  langid = {english},
  file = {/Users/didi/Zotero/storage/E26QP3XI/Madeira et al. - 2006 - Designing a Reinforcement Learning-Based Adaptive .pdf}
}

@misc{mialonAugmentedLanguageModels2023,
  title = {Augmented {{Language Models}}: A {{Survey}}},
  shorttitle = {Augmented {{Language Models}}},
  author = {Mialon, Grégoire and Dessì, Roberto and Lomeli, Maria and Nalmpantis, Christoforos and Pasunuru, Ram and Raileanu, Roberta and Rozière, Baptiste and Schick, Timo and {Dwivedi-Yu}, Jane and Celikyilmaz, Asli and Grave, Edouard and LeCun, Yann and Scialom, Thomas},
  year = {2023},
  month = feb,
  number = {arXiv:2302.07842},
  eprint = {2302.07842},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2302.07842},
  urldate = {2023-04-20},
  abstract = {This survey reviews works in which language models (LMs) are augmented with reasoning skills and the ability to use tools. The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter. LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. While adhering to a standard missing tokens prediction objective, such augmented LMs can use various, possibly non-parametric external modules to expand their context processing ability, thus departing from the pure language modeling paradigm. We therefore refer to them as Augmented Language Models (ALMs). The missing token objective allows ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks. In this work, after reviewing current advance in ALMs, we conclude that this new research direction has the potential to address common limitations of traditional LMs such as interpretability, consistency, and scalability issues.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/didi/Zotero/storage/T7W3NTQL/Mialon et al. - 2023 - Augmented Language Models a Survey.pdf;/Users/didi/Zotero/storage/3UF5ZBRB/2302.html}
}

@inproceedings{nelsonEvaluatingModelDrift2015,
  title = {Evaluating Model Drift in Machine Learning Algorithms},
  booktitle = {2015 {{IEEE Symposium}} on {{Computational Intelligence}} for {{Security}} and {{Defense Applications}} ({{CISDA}})},
  author = {Nelson, Kevin and Corbin, George and Anania, Mark and Kovacs, Matthew and Tobias, Jeremy and Blowers, Misty},
  year = {2015},
  month = may,
  pages = {1--8},
  issn = {2329-6275},
  doi = {10.1109/CISDA.2015.7208643},
  abstract = {Machine learning is rapidly emerging as a valuable technology thanks to its ability to learn patterns from large data sets and solve problems that are impossible to model using conventional programming logic. As machine learning techniques become more mainstream, they are being applied to a wider range of application domains. These algorithms are now trusted to make critical decisions in secure and adversarial environments such as healthcare, fraud detection, and network security, in which mistakes can be incredibly costly. They are also a critical component to most modern autonomous systems. However, the data driven approach utilized by these machine learning methods can prove to be a weakness if the data on which the models rely are corrupted by either nefarious or accidental means. Models that utilize on-line learning or periodic retraining to learn new patterns and account for data distribution changes are particularly susceptible to corruption through model drift. In modeling this type of scenario, specially crafted data points are added to the training set over time to adversely influence the system, inducing model drift which leads to incorrect classifications. Our work is focused on exploring the resistance of various machine learning algorithms to such an approach. In this paper we present an experimental framework designed to measure the susceptibility of anomaly detection algorithms to model drift. We also exhibit our preliminary results using various machine learning algorithms commonly found in intrusion detection research.},
  keywords = {adversarial machine learning,Algorithm design and analysis,cyber security,Data models,Hidden Markov models,Image color analysis,intrusion detection systems,Machine learning algorithms,model drift,Security,Training},
  file = {/Users/didi/Zotero/storage/PN4EQK8M/7208643.html}
}

@article{nelsonfordDecisionSupportSystems1985,
  title = {Decision Support Systems and Expert Systems: {{A}} Comparison},
  shorttitle = {Decision Support Systems and Expert Systems},
  author = {Nelson Ford, F.},
  year = {1985},
  month = jan,
  journal = {Information \& Management},
  volume = {8},
  number = {1},
  pages = {21--26},
  issn = {0378-7206},
  doi = {10.1016/0378-7206(85)90066-7},
  urldate = {2023-04-06},
  abstract = {In recent years there have been rapid developments in two technologies aimed at improving decision-making: decision support systems (DSS) and expert systems (ES). A DSS is an interactive system that helps decision-makers utilize data and models to solve unstructured or semi-structured problems. An ES is a problem-solving computer program that achieves good performance in a specialized problem domain that is considered difficult and requires specialized knowledge and skill. While both types seek to improve the quality of the decision, there are some distinct differences between the two. To understand and distinguish them, DSS and ES are compared in four primary areas: 1) objectives and intents, 2) operational differences, 3) users, and 4) development methodology.},
  langid = {english},
  keywords = {Decision Making Systems,Decision Support Systems,Expert Systems,Knowledge Based Systems},
  file = {/Users/didi/Zotero/storage/WLSVQ9LQ/0378720685900667.html}
}

@article{ostheimerAllianceHumansMachines2021,
  title = {An Alliance of Humans and Machines for Machine Learning: {{Hybrid}} Intelligent Systems and Their Design Principles},
  shorttitle = {An Alliance of Humans and Machines for Machine Learning},
  author = {Ostheimer, Julia and Chowdhury, Soumitra and Iqbal, Sarfraz},
  year = {2021},
  month = aug,
  journal = {Technology in Society},
  volume = {66},
  pages = {101647},
  issn = {0160-791X},
  doi = {10.1016/j.techsoc.2021.101647},
  urldate = {2023-04-04},
  abstract = {With the growing number of applications of artificial intelligence such as autonomous cars or smart industrial equipment, the inaccuracy of utilized machine learning algorithms could lead to catastrophic outcomes. Human-in-the-loop computing combines human and machine intelligence resulting in a hybrid intelligence of complementary strengths. Whereas machines are unbeatable in logic and computation speed, humans are contributing with their creative and dynamic minds. Hybrid intelligent systems are necessary to achieve high accuracy and reliability of machine learning algorithms. In a design science research project with a Swedish manufacturing company, this paper presents an application of human-in-the-loop computing to make operational processes more efficient. While conceptualizing a Smart Power Distribution for electric industrial equipment, this research presents a set of principles to design machine-learning algorithms for hybrid intelligence. From being AI-ready as an organization to clearly focusing on the customer benefits of a hybrid intelligent system, designers need to build and strengthen the trust in the human-AI relationship to make future applications successful and reliable. With the growing trends of technological advancements and incorporation of artificial intelligence in more and more applications, the alliance of humans and machines have become even more crucial.},
  langid = {english},
  keywords = {Artificial intelligence,Design principles,Design science research,Human-in-the-loop (HITL) computing,Hybrid intelligence,Machine learning},
  file = {/Users/didi/Zotero/storage/UM3CNAUJ/Ostheimer et al. - 2021 - An alliance of humans and machines for machine lea.pdf;/Users/didi/Zotero/storage/LJ8ZWARU/S0160791X21001226.html}
}

@article{perifanisInvestigatingInfluenceArtificial2023,
  title = {Investigating the {{Influence}} of {{Artificial Intelligence}} on {{Business Value}} in the {{Digital Era}} of {{Strategy}}: {{A Literature Review}}},
  shorttitle = {Investigating the {{Influence}} of {{Artificial Intelligence}} on {{Business Value}} in the {{Digital Era}} of {{Strategy}}},
  author = {Perifanis, Nikolaos-Alexandros and Kitsios, Fotis},
  year = {2023},
  month = feb,
  journal = {Information},
  volume = {14},
  number = {2},
  pages = {85},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2078-2489},
  doi = {10.3390/info14020085},
  urldate = {2023-04-06},
  abstract = {For organizations, the development of new business models and competitive advantages through the integration of artificial intelligence (AI) in business and IT strategies holds considerable promise. The majority of businesses are finding it difficult to take advantage of the opportunities for value creation while other pioneers are successfully utilizing AI. On the basis of the research methodology of Webster and Watson (2020), 139 peer-reviewed articles were discussed. According to the literature, the performance advantages, success criteria, and difficulties of adopting AI have been emphasized in prior research. The results of this review revealed the open issues and topics that call for further research/examination in order to develop AI capabilities and integrate them into business/IT strategies in order to enhance various business value streams. Organizations will only succeed in the digital transformation alignment of the present era by precisely adopting and implementing these new, cutting-edge technologies. Despite the revolutionary potential advantages that AI capabilities may promote, the resource orchestration, along with governance in this dynamic environment, is still complex enough and in the early stages of research regarding the strategic implementation of AI in organizations, which is the issue this review aims to address and, as a result, assist present and future organizations effectively enhance various business value outcomes.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {AI capability,artificial intelligence (AI),business strategy,business value,digital transformation,IT strategy},
  file = {/Users/didi/Zotero/storage/QCN4FQSM/Perifanis and Kitsios - 2023 - Investigating the Influence of Artificial Intellig.pdf}
}

@article{reimImplementationArtificialIntelligence2020,
  title = {Implementation of {{Artificial Intelligence}} ({{AI}}): {{A Roadmap}} for {{Business Model Innovation}}},
  shorttitle = {Implementation of {{Artificial Intelligence}} ({{AI}})},
  author = {Reim, Wiebke and Åström, Josef and Eriksson, Oliver},
  year = {2020},
  month = jun,
  journal = {AI},
  volume = {1},
  number = {2},
  pages = {180--191},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2673-2688},
  doi = {10.3390/ai1020011},
  urldate = {2023-04-27},
  abstract = {Technical advancements within the subject of artificial intelligence (AI) leads towards development of human-like machines, able to operate autonomously and mimic our cognitive behavior. The progress and interest among managers, academics and the public has created a hype among many industries, and many firms are investing heavily to capitalize on the technology through business model innovation. However, managers are left with little support from academia when aiming to implement AI in their firm’s operations, which leads to an increased risk of project failure and unwanted results. This paper aims to provide a deeper understanding of AI and how it can be used as a catalyst for business model innovation. Due to the increasing range and variety of the available published material, a literature review has been performed to gather current knowledge within AI business model innovation. The results are presented in a roadmap to guide the implementation of AI to firm’s operations. Our presented findings suggest four steps when implementing AI: (1) understand AI and organizational capabilities needed for digital transformation; (2) understand current BM, potential for BMI, and business ecosystem role; (3) develop and refine capabilities needed to implement AI; and (4) reach organizational acceptance and develop internal competencies.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {artificial intelligence,business model innovation,business models,implementation,road map},
  file = {/Users/didi/Zotero/storage/HZLAUP6P/Reim et al. - 2020 - Implementation of Artificial Intelligence (AI) A .pdf}
}

@misc{ResearchHybridIntelligence,
  title = {Research – {{The Hybrid Intelligence Centre}}},
  urldate = {2023-04-15},
  langid = {english},
  file = {/Users/didi/Zotero/storage/5LRYQLBG/research.html}
}

@article{RisingMachinesSociotechnical2020,
  title = {Rising with the Machines: {{A}} Sociotechnical Framework for Bringing Artificial Intelligence into the Organization},
  shorttitle = {Rising with the Machines},
  year = {2020},
  month = nov,
  journal = {Journal of Business Research},
  volume = {120},
  pages = {262--273},
  publisher = {{Elsevier}},
  issn = {0148-2963},
  doi = {10.1016/j.jbusres.2020.07.045},
  urldate = {2023-04-03},
  abstract = {Artificial intelligence (AI) is increasingly being adopted by organizations, yet implementation is often carried out without careful consideration of …},
  langid = {english},
  file = {/Users/didi/Zotero/storage/Q4RCXUAT/S0148296320305002.html}
}

@book{russel2010,
  title = {Artificial Intelligence: {{A}} Modern Approach},
  author = {Russell, Stuart and Norvig, Peter},
  year = {2010},
  edition = {Third},
  publisher = {{Prentice Hall}},
  added-at = {2020-02-01T18:23:11.000+0100},
  biburl = {https://www.bibsonomy.org/bibtex/20533b732950d1c5ab4ac12d4f32fe637/mialhoma},
  interhash = {53908a52dd4c6c8e39f93f4ffc8341be},
  intrahash = {0533b732950d1c5ab4ac12d4f32fe637},
  keywords = {ties4530},
  timestamp = {2020-02-01T18:23:11.000+0100}
}

@incollection{schlenkerMachineIntelligenceManagerial2020,
  title = {Machine {{Intelligence}} and {{Managerial Decision-Making}}},
  booktitle = {Data {{Analytics}} and {{AI}}},
  author = {Schlenker, Lee and Minhaj, Mohamed},
  year = {2020},
  publisher = {{Auerbach Publications}},
  abstract = {In this chapter, the authors explore how machine intelligence can improve human decision-making. They discusses on a certain number of normative assumptions. Analytics requires different types of “intelligence” that extend far beyond rational thinking. The objective of information technology isn’t to replace humanity, but to enrich human experience. Decision-making involves the selection of a course of action from among two or more possible alternatives in order to arrive at a solution for a given problem. In both personal and organizational decision-making, the objective is to choose the best available option within a given time constraint. Irrespective of the nature of management and the rungs of an organization, one critical success factor in any organization is the quality of its managerial decision-making. managerial decisions can be broadly classified into three categories, namely, strategic, tactical, and operational.},
  isbn = {978-1-00-301985-5}
}

@article{schmidtAugmentingHumanIntellect2017,
  title = {Augmenting {{Human Intellect}} and {{Amplifying Perception}} and {{Cognition}}},
  author = {Schmidt, Albrecht},
  year = {2017},
  month = jan,
  journal = {IEEE Pervasive Computing},
  volume = {16},
  number = {1},
  pages = {6--10},
  issn = {1558-2590},
  doi = {10.1109/MPRV.2017.8},
  abstract = {This first installment of the new Human Augmentation department looks at various technologies designed to augment the human intellect and amplify human perception and cognition. Linking back to early work in interactive computing, Albrecht Schmidt considers how novel technologies can create a new relationship between digital technologies and humans.},
  keywords = {Artificial intelligence,big data,Big data,Cognition,History,history of computing,human augmentation,Human computer interaction,human-computer interaction,Internet of things,Internet of Things,Mobile robots,pervasive computing,Pervasive computing,robotics,Sensors},
  file = {/Users/didi/Zotero/storage/4KW54E9Z/Schmidt - 2017 - Augmenting Human Intellect and Amplifying Percepti.pdf;/Users/didi/Zotero/storage/P9Y5JE4Z/references.html}
}

@article{seeberMachinesTeammatesResearch2020,
  title = {Machines as Teammates: {{A}} Research Agenda on {{AI}} in Team Collaboration},
  shorttitle = {Machines as Teammates},
  author = {Seeber, Isabella and Bittner, Eva and Briggs, Robert O. and {de Vreede}, Triparna and {de Vreede}, Gert-Jan and Elkins, Aaron and Maier, Ronald and Merz, Alexander B. and {Oeste-Reiß}, Sarah and Randrup, Nils and Schwabe, Gerhard and Söllner, Matthias},
  year = {2020},
  month = mar,
  journal = {Information \& Management},
  volume = {57},
  number = {2},
  pages = {103174},
  issn = {0378-7206},
  doi = {10.1016/j.im.2019.103174},
  urldate = {2023-04-13},
  abstract = {What if artificial intelligence (AI) machines became teammates rather than tools? This paper reports on an international initiative by 65 collaboration scientists to develop a research agenda for exploring the potential risks and benefits of machines as teammates (MaT). They generated 819 research questions. A subteam of 12 converged them to a research agenda comprising three design areas – Machine artifact, Collaboration, and Institution – and 17 dualities – significant effects with the potential for benefit or harm. The MaT research agenda offers a structure and archetypal research questions to organize early thought and research in this new area of study.},
  langid = {english},
  keywords = {Artificial intelligence,Design,Duality,Research agenda,Team collaboration},
  file = {/Users/didi/Zotero/storage/TC942YK2/Seeber et al. - 2020 - Machines as teammates A research agenda on AI in .pdf}
}

@misc{shiLanguageModelsAre2022,
  title = {Language {{Models}} Are {{Multilingual Chain-of-Thought Reasoners}}},
  author = {Shi, Freda and Suzgun, Mirac and Freitag, Markus and Wang, Xuezhi and Srivats, Suraj and Vosoughi, Soroush and Chung, Hyung Won and Tay, Yi and Ruder, Sebastian and Zhou, Denny and Das, Dipanjan and Wei, Jason},
  year = {2022},
  month = oct,
  number = {arXiv:2210.03057},
  eprint = {2210.03057},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2210.03057},
  urldate = {2023-04-20},
  abstract = {We evaluate the reasoning abilities of large language models in multilingual settings. We introduce the Multilingual Grade School Math (MGSM) benchmark, by manually translating 250 grade-school math problems from the GSM8K dataset (Cobbe et al., 2021) into ten typologically diverse languages. We find that the ability to solve MGSM problems via chain-of-thought prompting emerges with increasing model scale, and that models have strikingly strong multilingual reasoning abilities, even in underrepresented languages such as Bengali and Swahili. Finally, we show that the multilingual reasoning abilities of language models extend to other tasks such as commonsense reasoning and word-in-context semantic judgment. The MGSM benchmark is publicly available at https://github.com/google-research/url-nlp.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/didi/Zotero/storage/TZNZ8MSK/Shi et al. - 2022 - Language Models are Multilingual Chain-of-Thought .pdf;/Users/didi/Zotero/storage/RYIC3VK9/2210.html}
}

@article{shiSurveyTutorialHybrid2023,
  title = {Survey and {{Tutorial}} on {{Hybrid Human-Artificial Intelligence}}},
  author = {Shi, Feifei and Zhou, Fang and Liu, Hong and Chen, Liming and Ning, Huansheng},
  year = {2023},
  month = jun,
  journal = {Tsinghua Science and Technology},
  volume = {28},
  number = {3},
  pages = {486--499},
  publisher = {{清华大学出版社}},
  issn = {1007-0214},
  doi = {10.26599/TST.2022.9010022},
  urldate = {2023-04-09},
  abstract = {{$<$}p{$>$}The growing computing power, easy acquisition of large-scale data, and constantly improved algorithms have led to a new wave of artificial intelligence (AI) applications, which change the ways we live, manufacture, and do business. Along with this development, a rising concern is the relationship between AI and human intelligence, namely, whether AI systems may one day overtake, manipulate, or replace humans. In this paper, we introduce a novel concept named hybrid human-artificial intelligence (H-AI), which fuses human abilities and AI capabilities into a unified entity. It presents a challenging yet promising research direction that prompts secure and trusted AI innovations while keeping humans in the loop for effective control. We scientifically define the concept of H-AI and propose an evolution road map for the development of AI toward H-AI. We then examine the key underpinning techniques of H-AI, such as user profile modeling, cognitive computing, and human-in-the-loop machine learning. Afterward, we discuss H-AI’s potential applications in the area of smart homes, intelligent medicine, smart transportation, and smart manufacturing. Finally, we conduct a critical analysis of current challenges and open gaps in H-AI, upon which we elaborate on future research issues and directions.{$<$}/p{$>$}},
  langid = {english},
  file = {/Users/didi/Zotero/storage/CFTE7Z8Z/Shi et al. - 2023 - Survey and Tutorial on Hybrid Human-Artificial Int.pdf;/Users/didi/Zotero/storage/H2DB9UCH/Shi et al. - 2023 - Survey and Tutorial on Hybrid Human-Artificial Int.pdf}
}

@inproceedings{silvaDynamicDifficultyAdjustment2015,
  title = {Dynamic {{Difficulty Adjustment}} through an {{Adaptive AI}}},
  booktitle = {2015 14th {{Brazilian Symposium}} on {{Computer Games}} and {{Digital Entertainment}} ({{SBGames}})},
  author = {Silva, Mirna Paula and {do Nascimento Silva}, Victor and Chaimowicz, Luiz},
  year = {2015},
  month = nov,
  pages = {173--182},
  issn = {2159-6662},
  doi = {10.1109/SBGames.2015.16},
  abstract = {Dynamic Difficulty Adjustment (DDA) consists in an alternative to the static game balancing performed in game design. DDA is done during execution, tracking the player's performance and adjusting the game to present proper challenges to the player. This approach seems appropriate to increase the player entertainment, since it provides balanced challenges, avoiding boredom or frustration during the gameplay. This paper presents a mechanism to perform the dynamic difficulty adjustment during a game match. The idea is to dynamically change the game AI, adapting it to the player skills. We implemented three different AIs to match player behaviors: beginner, regular and experienced in the game Defense of the Ancient (DotA), a modification (MOD) of the game Warcraft III. We performed a series of experiments and, after comparing all results, the presented mechanism was able to keep up with the player's abilities on 85\% of all experiments. The remaining 15\% failed to suit the player's need because the adjustment did not occur on the right moment.},
  keywords = {Artificial intelligence,Artificial Intelligence,Digital Games,Dynamic Difficulty Adjustment,Dynamic Difficulty Balance,Entertainment,Entertainment industry,Games,Measurement,Monitoring,Psychology},
  file = {/Users/didi/Zotero/storage/ZMCAEKU8/Silva et al. - 2015 - Dynamic Difficulty Adjustment through an Adaptive .pdf;/Users/didi/Zotero/storage/QZVEKN5L/7785854.html}
}

@article{strouseCollaboratingHumansHuman2021,
  title = {Collaborating with {{Humans}} without {{Human Data}}},
  author = {Strouse, D. and McKee, Kevin R. and Botvinick, M. and Hughes, Edward and Everett, Richard},
  year = {2021},
  month = oct,
  journal = {ArXiv},
  urldate = {2023-04-17},
  abstract = {Collaborating with humans requires rapidly adapting to their individual strengths, weaknesses, and preferences. Unfortunately, most standard multi-agent reinforcement learning techniques, such as self-play (SP) or population play (PP), produce agents that overfit to their training partners and do not generalize well to humans. Alternatively, researchers can collect human data, train a human model using behavioral cloning, and then use that model to train"human-aware"agents ("behavioral cloning play", or BCP). While such an approach can improve the generalization of agents to new human co-players, it involves the onerous and expensive step of collecting large amounts of human data first. Here, we study the problem of how to train agents that collaborate well with human partners without using human data. We argue that the crux of the problem is to produce a diverse set of training partners. Drawing inspiration from successful multi-agent approaches in competitive domains, we find that a surprisingly simple approach is highly effective. We train our agent partner as the best response to a population of self-play agents and their past checkpoints taken throughout training, a method we call Fictitious Co-Play (FCP). Our experiments focus on a two-player collaborative cooking simulator that has recently been proposed as a challenge problem for coordination with humans. We find that FCP agents score significantly higher than SP, PP, and BCP when paired with novel agent and human partners. Furthermore, humans also report a strong subjective preference to partnering with FCP agents over all baselines.},
  file = {/Users/didi/Zotero/storage/7M2XDJDK/Strouse et al. - 2021 - Collaborating with Humans without Human Data.pdf}
}

@misc{swamyContextualDynamicPrompting2023,
  title = {Contextual {{Dynamic Prompting}} for {{Response Generation}} in {{Task-oriented Dialog Systems}}},
  author = {Swamy, Sandesh and Tabari, Narges and Chen, Chacha and Gangadharaiah, Rashmi},
  year = {2023},
  month = feb,
  number = {arXiv:2301.13268},
  eprint = {2301.13268},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2301.13268},
  urldate = {2023-04-26},
  abstract = {Response generation is one of the critical components in task-oriented dialog systems. Existing studies have shown that large pre-trained language models can be adapted to this task. The typical paradigm of adapting such extremely large language models would be by fine-tuning on the downstream tasks which is not only time-consuming but also involves significant resources and access to fine-tuning data. Prompting (Schick and Sch\textbackslash "utze, 2020) has been an alternative to fine-tuning in many NLP tasks. In our work, we explore the idea of using prompting for response generation in task-oriented dialog systems. Specifically, we propose an approach that performs contextual dynamic prompting where the prompts are learnt from dialog contexts. We aim to distill useful prompting signals from the dialog context. On experiments with MultiWOZ 2.2 dataset (Zang et al., 2020), we show that contextual dynamic prompts improve response generation in terms of combined score (Mehri et al., 2019) by 3 absolute points, and a massive 20 points when dialog states are incorporated. Furthermore, human annotation on these conversations found that agents which incorporate context were preferred over agents with vanilla prefix-tuning.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/didi/Zotero/storage/5KA6PIVY/Swamy et al. - 2023 - Contextual Dynamic Prompting for Response Generati.pdf;/Users/didi/Zotero/storage/ID8SSYZN/2301.html}
}

@misc{tamkinUnderstandingCapabilitiesLimitations2021,
  title = {Understanding the {{Capabilities}}, {{Limitations}}, and {{Societal Impact}} of {{Large Language Models}}},
  author = {Tamkin, Alex and Brundage, Miles and Clark, Jack and Ganguli, Deep},
  year = {2021},
  month = feb,
  number = {arXiv:2102.02503},
  eprint = {2102.02503},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2102.02503},
  urldate = {2023-04-20},
  abstract = {On October 14th, 2020, researchers from OpenAI, the Stanford Institute for Human-Centered Artificial Intelligence, and other universities convened to discuss open research questions surrounding GPT-3, the largest publicly-disclosed dense language model at the time. The meeting took place under Chatham House Rules. Discussants came from a variety of research backgrounds including computer science, linguistics, philosophy, political science, communications, cyber policy, and more. Broadly, the discussion centered around two main questions: 1) What are the technical capabilities and limitations of large language models? 2) What are the societal effects of widespread use of large language models? Here, we provide a detailed summary of the discussion organized by the two themes above.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/didi/Zotero/storage/QRMC5NP2/Tamkin et al. - 2021 - Understanding the Capabilities, Limitations, and S.pdf;/Users/didi/Zotero/storage/NPFXZTNZ/2102.html}
}

@article{terblancheComparingArtificialIntelligence2022,
  title = {Comparing Artificial Intelligence and Human Coaching Goal Attainment Efficacy},
  author = {Terblanche, Nicky and Molyn, Joanna and de Haan, Erik and Nilsson, Viktor O.},
  year = {2022},
  month = jun,
  journal = {PLOS ONE},
  volume = {17},
  number = {6},
  pages = {e0270255},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0270255},
  urldate = {2023-04-13},
  abstract = {The history of artificial intelligence (AI) is filled with hype and inflated expectations. Notwithstanding, AI is finding its way into numerous aspects of humanity including the fast-growing helping profession of coaching. Coaching has been shown to be efficacious in a variety of human development facets. The application of AI in a narrow, specific area of coaching has also been shown to work. What remains uncertain, is how the two compare. In this paper we compare two equivalent longitudinal randomised control trial studies that measured the increase in clients’ goal attainment as a result of having received coaching over a 10-month period. The first study involved human coaches and the replication study used an AI chatbot coach. In both studies, human coaches and the AI coach were significantly more effective in helping clients reach their goals compared to the two control groups. Surprisingly however, the AI coach was as effective as human coaches at the end of the trials. We interpret this result using AI and goal theory and present three significant implications: AI coaching could be scaled to democratize coaching; AI coaching could grow the demand for human coaching; and AI could replace human coaches who use simplistic, model-based coaching approaches. At present, AI’s lack of empathy and emotional intelligence make human coaches irreplicable. However, understanding the efficacy of AI coaching relative to human coaching may promote the focused use of AI, to the significant benefit of society.},
  langid = {english},
  keywords = {Artificial intelligence,Emotions,Human intelligence,Interpersonal relationships,Professions,Replication studies,Surveys,Verbal communication},
  file = {/Users/didi/Zotero/storage/GLKW2PK6/Terblanche et al. - 2022 - Comparing artificial intelligence and human coachi.pdf}
}

@article{todorovaNarrowAIContext2020,
  title = {"{{Narrow AI}}" in the {{Context}} of {{AI Implementation}}, {{Transformation}} and the {{End}} of {{Some Jobs}}},
  author = {Todorova, Mariana},
  year = {2020},
  journal = {Nauchni trudove},
  number = {4},
  pages = {15--25},
  publisher = {{University of National and World Economy, Sofia, Bulgaria}},
  urldate = {2023-04-17},
  abstract = {The article reviews how the appearance of the â€œartificial narrow intelligenceâ€ , which is already a fact, will participate in the processes of the transformation, the disappearance of some jobs and the creation of others. The aim of the text is to reveal two scenarios: optimistic and pessimistic as well as the basic theses in the debate of these problems. The tasks of the article are to draw the chances and to warn for the risks at the same time that follow of the implementation of AI in different human realms. The methodology of the research includes: a comparative analysis, key trends tracking, building of two alternative scenario forecasts. The originality of the text contains in the concrete placement of the Narrow AI in the context of the transformation of one the key human activity as labor is.},
  langid = {english},
  keywords = {artificial narrow intelligence,future of jobs,jobs transformation,new skills}
}

@article{vanbekkumModularDesignPatterns2021,
  title = {Modular Design Patterns for Hybrid Learning and Reasoning Systems},
  author = {{van Bekkum}, Michael and {de Boer}, Maaike and {van Harmelen}, Frank and {Meyer-Vitali}, André and ten Teije, Annette},
  year = {2021},
  month = sep,
  journal = {Applied Intelligence},
  volume = {51},
  number = {9},
  pages = {6528--6546},
  issn = {1573-7497},
  doi = {10.1007/s10489-021-02394-3},
  urldate = {2023-04-07},
  abstract = {The unification of statistical (data-driven) and symbolic (knowledge-driven) methods is widely recognized as one of the key challenges of modern AI. Recent years have seen a large number of publications on such hybrid neuro-symbolic AI systems. That rapidly growing literature is highly diverse, mostly empirical, and is lacking a unifying view of the large variety of these hybrid systems. In this paper, we analyze a large body of recent literature and we propose a set of modular design patterns for such hybrid, neuro-symbolic systems. We are able to describe the architecture of a very large number of hybrid systems by composing only a small set of elementary patterns as building blocks. The main contributions of this paper are: 1) a taxonomically organised vocabulary to describe both processes and data structures used in hybrid systems; 2) a set of 15+ design patterns for hybrid AI systems organized in a set of elementary patterns and a set of compositional patterns; 3) an application of these design patterns in two realistic use-cases for hybrid AI systems. Our patterns reveal similarities between systems that were not recognized until now. Finally, our design patterns extend and refine Kautz’s earlier attempt at categorizing neuro-symbolic architectures.},
  langid = {english},
  keywords = {Design patterns,Neuro-symbolic systems}
}

@misc{weiChainofThoughtPromptingElicits2023,
  title = {Chain-of-{{Thought Prompting Elicits Reasoning}} in {{Large Language Models}}},
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  year = {2023},
  month = jan,
  number = {arXiv:2201.11903},
  eprint = {2201.11903},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2201.11903},
  urldate = {2023-04-27},
  abstract = {We explore how generating a chain of thought -- a series of intermediate reasoning steps -- significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/didi/Zotero/storage/KYC22PRV/Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in La.pdf;/Users/didi/Zotero/storage/AFQR8AST/2201.html}
}

@misc{weiEmergentAbilitiesLarge2022,
  title = {Emergent {{Abilities}} of {{Large Language Models}}},
  author = {Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and Chi, Ed H. and Hashimoto, Tatsunori and Vinyals, Oriol and Liang, Percy and Dean, Jeff and Fedus, William},
  year = {2022},
  month = oct,
  number = {arXiv:2206.07682},
  eprint = {2206.07682},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2206.07682},
  urldate = {2023-04-20},
  abstract = {Scaling up language models has been shown to predictably improve performance and sample efficiency on a wide range of downstream tasks. This paper instead discusses an unpredictable phenomenon that we refer to as emergent abilities of large language models. We consider an ability to be emergent if it is not present in smaller models but is present in larger models. Thus, emergent abilities cannot be predicted simply by extrapolating the performance of smaller models. The existence of such emergence implies that additional scaling could further expand the range of capabilities of language models.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/didi/Zotero/storage/2KHQGAKI/Wei et al. - 2022 - Emergent Abilities of Large Language Models.pdf;/Users/didi/Zotero/storage/8H33Y8TY/2206.html}
}

@incollection{witschelVisualizationPatternsHybrid2021,
  title = {Visualization of {{Patterns}} for {{Hybrid Learning}} and {{Reasoning}} with {{Human Involvement}}},
  booktitle = {New {{Trends}} in {{Business Information Systems}} and {{Technology}}: {{Digital Innovation}} and {{Digital Business Transformation}}},
  author = {Witschel, Hans Friedrich and Pande, Charuta and Martin, Andreas and Laurenzi, Emanuele and Hinkelmann, Knut},
  editor = {Dornberger, Rolf},
  year = {2021},
  series = {Studies in {{Systems}}, {{Decision}} and {{Control}}},
  pages = {193--204},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-48332-6_13},
  urldate = {2023-04-08},
  abstract = {“Boxology” is the graphical representation of patterns that are commonly observed in hybrid learning and reasoning systems. Since some hybrid systems also involve humans-in-the-loop, a need to identify patterns including humans is foreseen. With the help of use cases that involve humans-in-the-loop, this chapter provides a discussion on the typical roles performed by humans in hybrid systems and how they influence machine learning and/or knowledge engineering activities. As a result, it introduces a new element in boxology to represent a human and identify two abstract patterns for such human-in-the-loop scenarios.},
  isbn = {978-3-030-48332-6},
  langid = {english},
  keywords = {Boxology,Hybrid intelligence,Knowledge engineering,Knowledge representation,Machine learning},
  file = {/Users/didi/Zotero/storage/L7UIBM4V/Witschel et al. - 2021 - Visualization of Patterns for Hybrid Learning and .pdf}
}

@article{xuCanArtificialIntelligence2021,
  title = {Can {{Artificial Intelligence Improve Firms}}’ {{Competitiveness}} during the {{COVID-19 Pandemic}}: {{International Evidence}}},
  shorttitle = {Can {{Artificial Intelligence Improve Firms}}’ {{Competitiveness}} during the {{COVID-19 Pandemic}}},
  author = {Xu, Da and Guo, Ye and Huang, Mengqi},
  year = {2021},
  month = aug,
  journal = {Emerging Markets Finance and Trade},
  volume = {57},
  number = {10},
  pages = {2812--2825},
  publisher = {{Routledge}},
  issn = {1540-496X},
  doi = {10.1080/1540496X.2021.1899911},
  urldate = {2023-04-06},
  abstract = {We conduct a textual analysis of 0.9 million product announcements to examine how artificial intelligence (AI) is reshaping market competition during the COVID-19 pandemic. We find that the revenues for firms that were engaged in AI before the pandemic increased faster in 2020. This effect is potentially due to the increased human digital footprint and is stronger in developing countries and countries with better property rights protection. Overall, our study has implications for practitioners and policymakers about the benefits of applying AI and cautions against blindly pursuing AI without considering national backgrounds.},
  keywords = {Artificial intelligence,COVID-19,developed and developing countries,F23,L25,market competition,O14,property right},
  file = {/Users/didi/Zotero/storage/VPWUSVBT/Xu et al. - 2021 - Can Artificial Intelligence Improve Firms’ Competi.pdf}
}

@misc{yaoReActSynergizingReasoning2023,
  title = {{{ReAct}}: {{Synergizing Reasoning}} and {{Acting}} in {{Language Models}}},
  shorttitle = {{{ReAct}}},
  author = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  year = {2023},
  month = mar,
  number = {arXiv:2210.03629},
  eprint = {2210.03629},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2210.03629},
  urldate = {2023-04-05},
  abstract = {While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components. Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34\% and 10\% respectively, while being prompted with only one or two in-context examples. Project site with code: https://react-lm.github.io},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/didi/Zotero/storage/MJR5QB24/Yao et al. - 2023 - ReAct Synergizing Reasoning and Acting in Languag.pdf;/Users/didi/Zotero/storage/NNIG59F9/2210.html}
}

@article{zanzottoViewpointHumanintheloopArtificial2019,
  title = {Viewpoint: {{Human-in-the-loop Artificial Intelligence}}},
  shorttitle = {Viewpoint},
  author = {Zanzotto, Fabio Massimo},
  year = {2019},
  month = feb,
  journal = {Journal of Artificial Intelligence Research},
  volume = {64},
  pages = {243--252},
  issn = {1076-9757},
  doi = {10.1613/jair.1.11345},
  urldate = {2023-04-13},
  abstract = {Little by little, newspapers are revealing the bright future that Artificial Intelligence (AI) is building. Intelligent machines will help everywhere. However, this bright future may have a possible dark side: a dramatic job market contraction before its unpredictable transformation. Hence, in a near future, large numbers of job seekers may need financial support while catching up with these novel unpredictable jobs. This possible job market crisis has an antidote inside. In fact, the rise of AI is sustained by the biggest knowledge theft of the recent years. Many learning AI machines are extracting knowledge from unaware skilled or unskilled workers by analyzing their interactions. By passionately doing their jobs, many of these workers are shooting themselves in the feet. In this paper, we propose Human-in-the-loop Artificial Intelligence (HitAI) as a fairer paradigm for AI systems. Recognizing that any AI system has humans in the loop, HitAI will reward these aware and unaware knowledge producers with a different scheme: decisions of AI systems generating revenues will repay the legitimate owners of the knowledge used for taking those decisions. As modern Merry Men, HitAI researchers should fight for a fairer Robin Hood Artificial Intelligence that gives back what it steals. This article is part of the special track on AI and Society.},
  copyright = {Copyright (c) 0},
  langid = {english},
  file = {/Users/didi/Zotero/storage/CC7SFUVU/Zanzotto - 2019 - Viewpoint Human-in-the-loop Artificial Intelligen.pdf}
}

@article{zhangArtificialIntelligenceRecommender2021,
  title = {Artificial Intelligence in Recommender Systems},
  author = {Zhang, Qian and Lu, Jie and Jin, Yaochu},
  year = {2021},
  month = feb,
  journal = {Complex \& Intelligent Systems},
  volume = {7},
  number = {1},
  pages = {439--457},
  issn = {2198-6053},
  doi = {10.1007/s40747-020-00212-w},
  urldate = {2023-04-22},
  abstract = {Recommender systems provide personalized service support to users by learning their previous behaviors and predicting their current preferences for particular products. Artificial intelligence (AI), particularly computational intelligence and machine learning methods and algorithms, has been naturally applied in the development of recommender systems to improve prediction accuracy and solve data sparsity and cold start problems. This position paper systematically discusses the basic methodologies and prevailing techniques in recommender systems and how AI can effectively improve the technological development and application of recommender systems. The paper not only reviews cutting-edge theoretical and practical contributions, but also identifies current research issues and indicates new research directions. It carefully surveys various issues related to recommender systems that use AI, and also reviews the improvements made to these systems through the use of such AI approaches as fuzzy techniques, transfer learning, genetic algorithms, evolutionary algorithms, neural networks and deep learning, and active learning. The observations in this paper will directly support researchers and professionals to better understand current developments and new directions in the field of recommender systems using AI.},
  langid = {english},
  keywords = {Artificial intelligence,Computational intelligence,Recommender systems},
  file = {/Users/didi/Zotero/storage/FS2RNH6C/Zhang et al. - 2021 - Artificial intelligence in recommender systems.pdf}
}

@article{zhangRecommendingGraphsComprehensive2023,
  title = {Recommending on Graphs: A Comprehensive Review from a Data Perspective},
  shorttitle = {Recommending on Graphs},
  author = {Zhang, Lemei and Liu, Peng and Gulla, Jon Atle},
  year = {2023},
  month = mar,
  journal = {User Modeling and User-Adapted Interaction},
  issn = {1573-1391},
  doi = {10.1007/s11257-023-09359-w},
  urldate = {2023-04-17},
  abstract = {Recent advances in graph-based learning approaches have demonstrated their effectiveness in modelling users’ preferences and items’ characteristics for Recommender Systems (RSs). Most of the data in RSs can be organized into graphs where various objects (e.g. users, items, and attributes) are explicitly or implicitly connected and influence each other via various relations. Such a graph-based organization brings benefits to exploiting potential properties in graph learning (e.g. random walk and network embedding) techniques to enrich the representations of the user and item nodes, which is an essential factor for successful recommendations. In this paper, we provide a comprehensive survey of Graph Learning-based Recommender Systems (GLRSs). Specifically, we start from a data-driven perspective to systematically categorize various graphs in GLRSs and analyse their characteristics. Then, we discuss the state-of-the-art frameworks with a focus on the graph learning module and how they address practical recommendation challenges such as scalability, fairness, diversity, explainability, and so on. Finally, we share some potential research directions in this rapidly growing area.},
  langid = {english},
  keywords = {Graph learning,Graph neural network,Recommender system},
  file = {/Users/didi/Zotero/storage/K5PSEL6U/Zhang et al. - 2023 - Recommending on graphs a comprehensive review fro.pdf}
}

@article{zhaoRoleAdaptationCollective2022,
  title = {The {{Role}} of {{Adaptation}} in {{Collective Human}}–{{AI Teaming}}},
  author = {Zhao, Michelle and Simmons, Reid and Admoni, Henny},
  year = {2022},
  journal = {Topics in Cognitive Science},
  volume = {2022},
  issn = {1756-8765},
  doi = {10.1111/tops.12633},
  urldate = {2023-04-17},
  abstract = {This paper explores a framework for defining artificial intelligence (AI) that adapts to individuals within a group, and discusses the technical challenges for collaborative AI systems that must work with different human partners. Collaborative AI is not one-size-fits-all, and thus AI systems must tune their output based on each human partner's needs and abilities. For example, when communicating with a partner, an AI should consider how prepared their partner is to receive and correctly interpret the information they are receiving. Forgoing such individual considerations may adversely impact the partner's mental state and proficiency. On the other hand, successfully adapting to each person's (or team member's) behavior and abilities can yield performance benefits for the human–AI team. Under this framework, an AI teammate adapts to human partners by first learning components of the human's decision-making process and then updating its own behaviors to positively influence the ongoing collaboration. This paper explains the role of this AI adaptation formalism in dyadic human–AI interactions and examines its application through a case study in a simulated navigation domain.},
  langid = {english},
  keywords = {Adaptation,Human robot interaction,Human–AI teaming,Human–robot collaboration},
  file = {/Users/didi/Zotero/storage/6TSLCNFX/Zhao et al. - The Role of Adaptation in Collective Human–AI Team.pdf;/Users/didi/Zotero/storage/KNV6AFY6/tops.html}
}

@article{zhouIntelligenceAugmentationBuilding2021,
  title = {Intelligence {{Augmentation}}: {{Towards Building Human-Machine Symbiotic Relationship}}},
  shorttitle = {Intelligence {{Augmentation}}},
  author = {Zhou, Lina and Paul, Souren and Demirkan, Haluk and Yuan, Lingyao and Spohrer, Jim and Zhou, Michelle and Basu, Julie},
  year = {2021},
  month = jun,
  journal = {AIS Transactions on Human-Computer Interaction},
  volume = {13},
  number = {2},
  pages = {243--264},
  issn = {1944-3900},
  doi = {10.17705/1thci.00149},
  file = {/Users/didi/Zotero/storage/3AGWIFQB/Zhou et al. - 2021 - Intelligence Augmentation Towards Building Human-.pdf;/Users/didi/Zotero/storage/YNCRFHIG/5.html}
}

@misc{zhouLeasttoMostPromptingEnables2023,
  title = {Least-to-{{Most Prompting Enables Complex Reasoning}} in {{Large Language Models}}},
  author = {Zhou, Denny and Schärli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and Chi, Ed},
  year = {2023},
  month = apr,
  number = {arXiv:2205.10625},
  eprint = {2205.10625},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2205.10625},
  urldate = {2023-04-26},
  abstract = {Chain-of-thought prompting has demonstrated remarkable performance on various natural language reasoning tasks. However, it tends to perform poorly on tasks which requires solving problems harder than the exemplars shown in the prompts. To overcome this challenge of easy-to-hard generalization, we propose a novel prompting strategy, least-to-most prompting. The key idea in this strategy is to break down a complex problem into a series of simpler subproblems and then solve them in sequence. Solving each subproblem is facilitated by the answers to previously solved subproblems. Our experimental results on tasks related to symbolic manipulation, compositional generalization, and math reasoning reveal that least-to-most prompting is capable of generalizing to more difficult problems than those seen in the prompts. A notable finding is that when the GPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve the compositional generalization benchmark SCAN in any split (including length split) with an accuracy of at least 99\% using just 14 exemplars, compared to only 16\% accuracy with chain-of-thought prompting. This is particularly noteworthy because neural-symbolic models in the literature that specialize in solving SCAN are trained on the entire training set containing over 15,000 examples. We have included prompts for all the tasks in the Appendix.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/didi/Zotero/storage/TQ5IMB8R/Zhou et al. - 2023 - Least-to-Most Prompting Enables Complex Reasoning .pdf;/Users/didi/Zotero/storage/ALW63HK3/2205.html}
}

@misc{zhouRevisitingAutomatedPrompting2023,
  title = {Revisiting {{Automated Prompting}}: {{Are We Actually Doing Better}}?},
  shorttitle = {Revisiting {{Automated Prompting}}},
  author = {Zhou, Yulin and Zhao, Yiren and Shumailov, Ilia and Mullins, Robert and Gal, Yarin},
  year = {2023},
  month = apr,
  number = {arXiv:2304.03609},
  eprint = {2304.03609},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2304.03609},
  urldate = {2023-04-22},
  abstract = {Current literature demonstrates that Large Language Models (LLMs) are great few-shot learners, and prompting significantly increases their performance on a range of downstream tasks in a few-shot learning setting. An attempt to automate human-led prompting followed, with some progress achieved. In particular, subsequent work demonstrates automation can outperform fine-tuning in certain K-shot learning scenarios. In this paper, we revisit techniques for automated prompting on six different downstream tasks and a larger range of K-shot learning settings. We find that automated prompting does not consistently outperform simple manual prompts. Our work suggests that, in addition to fine-tuning, manual prompts should be used as a baseline in this line of research.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/didi/Zotero/storage/3I6XF3T4/Zhou et al. - 2023 - Revisiting Automated Prompting Are We Actually Do.pdf;/Users/didi/Zotero/storage/7D34HI82/2304.html}
}
